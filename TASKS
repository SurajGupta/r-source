                           THE R TASK LIST

             ``Somebody, somebody has to, you see ...''
                  The Cat in the Hat Comes Back.


----------------------------------------------------------------------
TASK:	Multiple Graphics Device Drivers
STATUS:	Open
FROM:	Everyone
	R needs to have mutiple active device drivers and a means for
	copying pictures from one device to another. Etc. Etc.
	[ This is a medium-sized task.  It would be most useful to     ]
	[ do this in conjunction with moving to an event driven model. ]
	[ Greg Warnes has written some code which maintains, a device  ]
	[ "display list".  How much memory this might devour in the    ]
	[ multiple device case is an open question.  There is also     ]
	[ the question of what to do about the graphics parameters.    ]
	[ Should each device maintain a complete "par" state, or       ]
	[ should some parameters (like col, lty, font ...) be global.  ]
	[ Could a user have any memory of the last values in effect    ]
	[ for a driver which had been idle for a while.                ]

----------------------------------------------------------------------
TASK:	Mathlib checks
STATUS:	Open
FROM:	R@stat.auckland.ac.nz
	The numerical libraries and random number generators could
	do with a real had check.  Grunt work, but necessary.

----------------------------------------------------------------------
TASK:	List printing
STATUS:	Closed
FROM:	R@stat.auckland.ac.nz
	If an attribute is list valued, its components should print
	as follows.
		attr(,fred)$x
	rather than as
		attr(,fred)
		$x
	[ This problem plus some other formatting problems for    ]
	[ recursive structures have been fixed.  R printing looks ]
	[ very much like S now.					  ]

----------------------------------------------------------------------
TASK:	complex gamma and log gamma function not implemented
STATUS:	Open
FROM:	R@stat.auckland.ac.nz
	[ This is quite low priority.  Complain if you need it.  ]
	[ The Fullerton library has complex gamma function code. ]

----------------------------------------------------------------------
TASK:	solution of complex linear systems
STATUS:	Open
FROM:	R@stat.auckland.ac.nz
	[ Really just a matter of grabbing the correct linpack code. ]
	[ How general do we want to be here ...                      ]

----------------------------------------------------------------------
TASK:	eigenvalues and eigenvectors for general systems
STATUS:	Closed
FROM:	R@stat.auckland.ac.nz
	[ Really just a matter of grabbing the correct eispack code. ]

----------------------------------------------------------------------
TASK:	"update" for lm and glm models
STATUS:	Closed
FROM:	jlindsey@luc.ac.be
	First something from 0.12 that I forgot to report:
	update() for a formula works with lm() but not glm()
	for which it (still in 0.13) gives
	"Error in update.formula(call$formula,formula) ..."
	[ See also Thomas Lumley's problems; added better checking. RG]

----------------------------------------------------------------------
TASK:	"nlm" documentation inaccuracies
STATUS:	Open
FROM:	jlindsey@luc.ac.be
	The help for nlm is still called minimize although the
	contents have been updated. As well, when an illegal
	value is fed to nlm, the error message contains msg
	instead of print.level.
	[ The documentation looks ok.  The function needs to be ]
	[ rewritten so that it uses derivative information.     ]

----------------------------------------------------------------------
TASK:	"data.entry" problems
STATUS:	Open
FROM:	p.dalgaard@kubism.ku.dk
	the as.character problem in de() - probably better to fix even
	though it does make lists out of frames.
	there's no way to change a data value to NA in data.entry, etc.
	... earlier message ...
	(Peter Dalgaard) data.entry et al do not seem to have been
	adjusted for the new data frame structure.  This is actually
	a problem where a list is passed where a vector of character
	strings is expected.  To fix it change
		snames <- substitute(list(...))[-1]
	to
		snames <- as.character(substitute(list(...))[-1])
	However, there needs to be a look at the de... code.  When
	a data frame is edited it is returned as a list.  This can
	be cured with judicious use of "data.frame".
	[ The indicated change has been made, but other changes ]
	[ are needed.                                           ]

----------------------------------------------------------------------
TASK:	"x11" printcommand
STATUS: Open
FROM:	maechler@stat.math.ethz.ch
	There is in theory a "printcommand" argument to x11, which
	is ignored.  Make it do something.

----------------------------------------------------------------------
TASK:	"source" requires a terminating newline on EOF
STATUS:	Open
FROM:	Kurt.Hornik@ci.tuwien.ac.at
	source() fails in many cases where a file has no final
	newline.  (R&R, sorry for being ridiculouly nasty about
	things that don't work for files without a final newline.
	I have Emacs' next-line-add-newlines set to nil ...)
	This seems to be a problem with parse() in src/main/source.c
	in combo with the code in gram.y ...
	I know this is NOT something to quickly fix over the weekend.
	Please simply put it into your PROJECTS file.

----------------------------------------------------------------------
TASK:	problem with "glm" with binomial errors
STATUS:	Closed
FROM:	p.dalgaard@kubism.ku.dk
	in glm(,binomial) it's possible that loss of significant
	digits make expected values 0 or 1 even though there's no
	divergence of the fit.  (Happened to me with menarche data,
	infants and grown-ups included)
	[ Fixes received Thomas Lumley. ]

----------------------------------------------------------------------
TASK:	Errors in "parse" and "source"
STATUS:	Closed
FROM:	plummer@iarc.fr
	#4) If you put a few lines of comments at the start of a
	function, then the comments always appear *after* the first
	line of code.
	[ This needs a bit of a look.  Comments are a pain.      ]
	[ Later: Some progress made on this.  We need to look at ]
	[ preserving comments befor functions.                   ]

----------------------------------------------------------------------
TASK:	help file ALIAS() and LINK() constructions
STATUS:	Open
FROM:	R@stat.auckland.ac.nz
	How do we know which file to LINK to?  There needs to a step
	which fills in the file name on the basis of all ALIAS
	declarations.
	[ A proprocessing step is needed.  First we build a table  ]
	[ of aliases and corresponding file names.  Then we pass   ]
	[ throught the files building the correct LINK references. ]

----------------------------------------------------------------------
TASK:	"paste" problem
STATUS:	Open
FROM:	maechler@stat.math.ethz.ch
	in S,
		paste(....., collapse = string)
	always returns ONE string  (a character vector of length 1),
	according to documentation and several examples.
	in R, this is not true:
		R> paste(rep(" ",0), collapse="...") #anything for collapse
		character(0)
		S> paste(rep(" ",0), collapse="...") #anything for collapse
		[1] ""
	Again, I think  R  is more logical than S here, but it was decided
	that in minor cases, compatibility comes first...
	[ Low priority.  Complain if you really need it. ]

----------------------------------------------------------------------
TASK:	missing functionality - modelling
STATUS:	Open
FROM:	maechler@stat.math.ethz.ch
	aov,  print.aov, summary.aov,...  (!)
	which I really missed for teaching  a few months ago.
	[ We'll get to this - it actually should be fun. ]

----------------------------------------------------------------------
TASK:	warnings option
STATUS:	Open
FROM:	maechler@stat.math.ethz.ch
	which reminds me that we/I also would like something similar as S's
	options(warn = k)
	k=  0 : [default]  print warnings
	k= -1 :	do nothing (maybe append warnings to some temp-file)
	k=  1 : produce an error ('warning' becomes 'stop'). 

----------------------------------------------------------------------
TASK:	R has no stderr
STATUS:	Open
FROM:	Friedrich.Leisch@ci.tuwien.ac.at
	When I invoke R like
		R 2>errlog
	I would error messages expect to go to the file errlog
	instead of the screen.
	[ We don't have standard error.  This is problematic on ]
	[ platforms other than Unix.                            


----------------------------------------------------------------------
TASK:	deprecated
STATUS:	Closed
FROM:	maechler@stat.math.ethz.ch
	As I mentioned in a recent mail,
	I just saw that  0.16.1 does not contain  'deprecated' anymore,
	even though the function still exists.
	[ I don't think we need deprecated anymore. ]

----------------------------------------------------------------------
TASK:	"print.default" fix
STATUS:	Open
FROM:	la-jassine@aix.pacwan.net
	When you fix print.default, please also add prefix=

----------------------------------------------------------------------
TASK:	"print.default" fix
STATUS:	Open
FROM:	jlindsey@luc.ac.be
	print.default in S has an option, right=T, but R does not

----------------------------------------------------------------------
TASK:	"postscript" fix
STATUS:	Open
FROM:	la-jassine@aix.pacwan.net
	postscript() also needs the options onefile, print.it, and
	append (even if they are not supported yet it would be nice if
	the arguments could be accepted and ignored).
	[ I added these as arguments, but they have no effect. ]

----------------------------------------------------------------------
TASK:	task scheduling
STATUS:	Open
FROM:	gwhite@cabot.bio.dfo.ca
	More generally, the range of things that can be done in R would
	be greater if there was a simple scheduling mechanism.  Is
	there a way to have a specific function invoked just before the
	command prompt returns after a function?  Such a function could
	be used to run save(...) or check for various external cues
	(update of a file's timestamp) to control an analysis.
	I doubt it would make sense to have full context switching in
	R,  but perhaps save() could be done in a way that would allow
	it to be used even in a long calculation under some timer
	control.  I expect the user would need to provide a list of the
	data objects that need to be saved.

----------------------------------------------------------------------
TASK:	Inf numerics
STATUS:	Open
FROM:	plummer@iarc.fr
	Could we have an Inf object in R? I would find it useful.
	[ Sigh.  I wish we had designed this in. ]
	[ It will be a pain to ADD.              ]

----------------------------------------------------------------------
TASK:	Verbose debugging mode
STATUS:	Closed
FROM:	plummer@iarc.fr
	It would be really nice to have a verbose mode for the debug
	function, which steps through each line automatically while
	printing each line to the screen. Currently I have to step
	through each line with the return key just to see where CODA
	crashes.  This can get very tedious as its a huge program.
	[ traceback() gets you this information. ]

----------------------------------------------------------------------
TASK:	Auto-save
STATUS:	Open
FROM:	<p.dalgaard@kubism.ku.dk> <hornik@ci.tuwien.ac.at>
	> BTW: How about putting auto-save-workspace on the task list?
	> Or just a manual save.work() currently, you can lose quite a
	> bit of work to an unexpected segfault. (And q()+restart is
	> cumbersome, esp. if you need to reattach subsetted dataframes, etc.)
	Perhaps call it save.image() instead and use
		save(list = ls(), file = ".RData")
	as was suggested some time ago?
	(Whatever the result is, it needs to go in the FAQ, which goes into
	great length about that under R data can get lost when a crash occurs,
	but does not say how to save them ...)

----------------------------------------------------------------------
TASK:	"chisquare.test" problem
STATUS:	Open
FROM:	<venkat@biosta.mskcc.org>
	Can you change the explicit "cat" statement in the
	"chisquare.test" function which insists on writing to the
	screen even when the output is redirected to a variable? (Using
	"htest" class as in "t.test" function.)
	[ Should we switch to the library one. ]

----------------------------------------------------------------------
TASK:	Graphics inconsistencies
STATUS: Openish
FROM:	Bill.Venables@adelaide.edu.au
	While transferring some old S-code I came across some minor
	inconsistencies between R and S that are probably more nuisance
	value than they would take to fix.  I report them here for
	reference, (but not in any campaigning mood, of course...)
	1. No frame() command in R and so no graceful way to clear a
	   plotting screen.  (Or is there?)
	   [ Added ]
	2. There is a dev.off() function, but no other dev.xxx functions.
	   (The dev.xxx group are S-PLUS and not vanilla S, by the way.)
	   There is no graphics.off() function.
	   [ Long-term project ]
	3. If dfr is a data frame with components "x", "y" and some
	   others then points(dfr) uses dfr as an xy-list in S but not in
	   R.  If there is some non-numeric component it actually fails
	   in R.  This may be S being a bit inconsistent, but the
	   behaviour is different.
	   [ Fixed? ]
	4. The plotting marks are a bit gappy in R and even the ones
	   that are there do not correspond to their S counterparts.
	   Here is a little function to make a wall chart showing the
	   gaps:
	   [ We now have all the S symbols and a new set of R ones. ]
		show.marks <- function()
		{
		  if(!exists(".Device") || is.null(.Device)) x11()
		  plot(1, type="n", axes=F, xlab="", ylab="")
		  oldpar <- par()
		  par(usr = c(-0.01, 5.01, -0.01, 5.01), pty = "s")
		  for(i in 0:18) {
		    x <- 1/2 + (i %% 5)
		    y <- 4.5 - (1/2 + (i %/% 5))
		    points(x + 1/5, y - 1/5, pch = i, cex = 3)
		    text(x - 1/5, y + 1/5, i, adj = 0.5, cex = 1.5)
		  }
		  abline(h = 1:5 - 0.5, lty = 1)
		  segments(0:5, rep(0.5, 5), 0:5, rep(4.5, 5))
		  par(oldpar)
		  invisible()
		}
	5. In S you may extend a list by assigning to a new component.
	   For example if lis has components "x" and "y", only, you can
	   extend it by assigning to lis$z, lis["z"] or lis[, "z] (the
	   last if it is also a data frame).  In R only the first of
	   these works; the others give a "subscript out of bounds"
	   error.  (This may have been discussed while I was not paying
	   attention, in which case I apologize.)
	   [ Fixed in 0.50. ]

----------------------------------------------------------------------
TASK:	Function pointer access
STATUS:	Open
FROM:	<schwarte@feat.mathematik.uni-essen.de>
	I want to report two problems with the Fortran code of R.
	1) Configure does not adapt GETSYMBOLS.in if the Fortran Compiler
	   does not add underscores to the symbol names.
	2) There is a name conflict if the Fortran Compiler does not add
	   underscores because there exist a Fortran function FMIN and a 
	   C function fmin(). Thus the name of the Fortran FMIN should be 
	   changed.
	   [ This is fixed I think. ]
	Currently I am rewriting my robust location-scale code in C. I
	intend to make this new code available as a library once a
	standard for such libraries has been agreed upon. As I would
	like to allow prospective users to experiment with private
	psi/chi functions I need access to the hash table of available
	function pointers. Is it possible that you insert a function
	into dotcode.c that contains the code fragment form lines 482
	to 495 and returns a function pointer?

----------------------------------------------------------------------
TASK:	Partial string matching
STATUS:	Open
FROM:	<R@stat.auckland.ac.nz>
	Is there an existing partial string match function which could
	be used in place of pstrmatch in subset.c???
	If not can pstrmatch take on the functions of all partial match
	functions?

----------------------------------------------------------------------
Post 0.49 Additions
----------------------------------------------------------------------
TASK:	Name Attributes on Calls
STATUS: Closed
FROM:	<p.dalgaard@kubism.ku.dk>
	A call with tagged arguments is something like a list, the tags
	can be used to access elements, but the names attribute is absent,
	until the call is coerced to a list. (Attempting to set the names()
	causes evaluation. Changing "list" to "blipblop" causes an 'Error:
	couldn't find function "blipblop"' at that point.)

	> j<-substitute(list(a=1, b=2))
	> j
	list(a = 1, b = 2)
	> j$b
	[1] 2
	> names(j)
	NULL
	> names(j)<-NULL
	> j
	[[1]]
	[1] 1

	[[2]]
	[1] 2
	[At least under SunOS this is fixed. RG]
----------------------------------------------------------------------
TASK:	Coercion to Call is Broken
STATUS:	Closed
FROM:	<p.dalgaard@kubism.ku.dk>
	This one is plainly a bug. Meaningless, but...
	> j<-as.call(list(a=1,b=2))
	> j
	Segmentation fault (core dumped)
	[The problem was with printing a LANG sxp with a tag that wasn't
	 a comment (actually a list of comments). RG]

----------------------------------------------------------------------
TASK:	"as.call" problem 
STATUS:	Closed
FROM:	<p.dalgaard@kubism.ku.dk>
	Strange... as.call should return its argument if is.call is true?
	> j<-substitute(list(a=1,b=2))
	> j
	list(a = 1, b = 2)
	> as.call(j)
	Error in as.call(j) : invalid argument list
	> is.call(j)
	[1] TRUE
	[It does now. RG]

----------------------------------------------------------------------
TASK:	String NAs Via the Back Door.
STATUS:	Open
FROM:	<p.dalgaard@kubism.ku.dk>
	Ok, the right solution seems to be names(as.list(j)), but then we run
	into some other fun with NA's... Shouldn't the real NA print without
	quotes?
	> ch[1]<-paste("N","A",sep="") 
	> is.na(ch)
	[1] FALSE FALSE FALSE
	> ch
	[1] "NA" "a"  "b" 
	> ch[1]=="NA"
	[1] TRUE
	> ch[1]<-"NA"                 
	> is.na(ch)
	[1]  TRUE FALSE FALSE

----------------------------------------------------------------------
TASK:	Directory Structure
STATUS:	Open
FROM:	<Kurt.Hornik@ci.tuwien.ac.at> + Friedrich + Paul Gilbert
	> Regarding the location of data for libraries it might be easier if
	> everything for one library is included in one subdirectory. At least
	> it would certainly be easier to clean-up, which I like to do every few
	> years.  Thus the code file, data, and any compiled code would be in
	> one subdirectory under $RHOME/library.
	Like
		library/<section>/
		library/<section>/data
		library/<section>/exec		(scripts and or binaries which
						 only make sense for the add-on)
		library/<section>/funs
		library/<section>/help
		library/<section>/html
		library/<section>/objs		(*.so)
	???
	> I realize this means a small change to the way libraries are now
	> found, but in the end I think it would be much cleaner.
	I think the changes would not be too hard, and we need to do something
	about the directory structure anyway.

	Actually, I think if R&R ok'ed something like that, Fritz and I would
	take a look.
	(In a way, I NEED to do something like that anyway, because I promised
	it for making an official Debian package ...)
	Would it mean that we also employ the S library/section concept?


----------------------------------------------------------------------
TASK:	Startup Processing
STATUS:	Open
FROM:	<p.dalgaard@kubism.ku.dk>
	The x11() window can be a nuisance to have popping up at startup (esp.
	on small screens) when you're not working with graphics. However,
	currently you can't get rid of it without modifying the systemwide
	Rprofile. 
	Current logic is:
	Run $RHOME/library/Rprofile
	if ./.Rprofile exists
		run it
	else if $HOME/.Rprofile exists
		run that
	endif
	I think it should be
	Run $RHOME/library/Rsetup
	if ./.Rprofile exists
		run it
	else if $HOME/.Rprofile exists
		run that
	else if $RHOME/library/Rprofile exists
		run that
	endif
	i.e. essential system initialisation goes in Rsetup, the rest in
	Rprofile, which can be overridden by the user. Currently, the line

	if(interactive()) x11()
	is the candidate to move from one to the other. BTW, it really should read
	if(interactive() && getenv("DISPLAY")!="") x11()
	[BTW2: getenv() implemented using system()? is that really necessary?]

  >>	<Kurt.Hornik@ci.tuwien.ac.at>
	I more or less agree, BUT:
	I'd like (in the future) to have the system-wide Rprofile searched in a
	site-specific location as well (similar to Emacs, following the idea of
	keeping the distribution and the site-specific things apart).
	So it would be
		system-wide Rsetup (which should basically be platform-specific
		  stuff, cause otherwise it could go into base as well?)
		if .Rprofile exists run it else
		if ~/.Rprofile exists run it else
		if Rprofile exists on the default library search path, run it
	and that search path could e.g. specify all `library' trees with a
	compile-time default of
		~/lib/R:/usr/local/lib/R/site:/usr/local/lib/R/${version}
	and settable at run time via e.g. the environment variable R_PATH.

----------------------------------------------------------------------
TASK:	Cut is incompatible
STATUS:	Closed
FROM:	<bates@stat.wisc.edu>
	As I recall the S-plus and S "cut" functions return length(breaks)
	when an element of x is equal to the maximum value of breaks.  The R
	version of "cut" calls the C function "bincode" which returns an NA
	for this situation then cut croaks trying to make a factor with the
	result.
	I can provide a detailed example if this would help.
	[ I added bincode2 which does intervals of the form (a,b] like S
	wants and an option right=TRUE to set these. RG]


----------------------------------------------------------------------
TASK:	Old Unfixed Problems
STATUS:	Open
FROM:	<Kurt.Hornik@ci.tuwien.ac.at>
	I noticed the following problems (all already reported, but not in
	TASKS).
	* TASKS.OLD has
        Btw, here's another way to produce a segfault with admittedly
        nonsense code:
                R> x <- 1:5
                R> dimnames(x)[1,2] <- NULL
                Segmentation fault
        [ Hmmm.  This seems to have gone away.  I get the error     ]
        [ message "Error: incorrect number of subscripts on array". ]
	[ Verified by Rossini ...]

	On my Linux system, I still get the segfault.  Perhaps others could
	check that?
	* File permissions in data should be 644.
	* In src/unix/system.c, one `Rdata' should be `RData' (d -> D).
	* The documentation for the noncentral chisquare distribution is not
	quite correct.  (rnchisq does not exist, the existing functions have x,
	df and the noncentrality parameter as args, and the density should be
	   pnchisq(x, df, lambda)
	   = exp(-lambda / 2)
	     * sum_{r=0}^\infty \frac{lambda^r}{2^r r!} pchisq(x, df + 2r)
	(semiTeX notation only, sorry).

----------------------------------------------------------------------
TASK:	New Problems
STATUS:	Open
FROM:	<Kurt.Hornik@ci.tuwien.ac.at>
	New minor remarks:
	* The documentation for `image' still has the old order z, x, y.
	* Perhaps one should add `par(ask = T)' in the image demo?
	* Perhaps one should save the original value of par() at the beginning
	of the graphics demo, and restore that at its end (s.t. typically asking
	is turned off again).

----------------------------------------------------------------------
TASK:	Incompatibilities
STATUS: Closed	
FROM:	<bates@stat.wisc.edu>
	While bringing up the extended Splines library of classes and methods
	that Bill and I created, I discovered the problem with "cut".  I will
	try to go back and resolve that from the sources in a clean way.

	There are two other minor gliches that I encountered.  S-plus has the
	moral equivalent of
	 coefficients.default <- function(x, ...) x$coefficients
	and 
	 as.data.frame <-
	   function(x, row.names = NULL, optional = F, ...)
	   UseMethod("as.data.frame")
	These would both be helpful to us.  Would you consider adding them or
	would you prefer that we do the customization ourselves?
	I think we will end up having to create separate source files for R
	and S-plus and Sv4 for some of our libraries.  I expect that the
	majority of the code can go into a "common" file then we might need to
	either create a sort of "ifdef" statement or put the "ifdef" stuff
	into other files.
	[ Added RG]

----------------------------------------------------------------------
TASK:	"rhyper"
STATUS:	Closed
FROM:	E. S. Venkatraman (venkat@biosta.mskcc.org)
	I reported bugs in "rhyper" and the TASKS.OLD file claims that
	they have been fixed. But R continues to get stuck (the prompt
	never comes back) if I use rhyper with N1, N2, n large, for
	example "rhyper(5,200,250,60)".
	[ Robert found a typo in the underlying generator.  Fixed. ]

----------------------------------------------------------------------
TASK:	Multiplatform Support
STATUS:	Open
FROM:	<warnes@biostat.washington.edu>
	I've modified the "$RHOME/bin/R" and "$RHOME/cmd/filename" so that you 
	can use the same directories for multiple machines.  That is, machines 
	running various flavors of UNIX can access the same directories.
	The modified structure adds the directories
		$RHOME/bin/$OSTYPE/
		$RHOME/lib/$OSTYPE/
	to hold the machine specific binaries.
	For instance, here the $RHOME directory contains two subdirectories,
		$RHOME/bin/solaris/
		$RHOME/bin/sunos4/
	which each hold the appropriate R.binary file.  
	These two modified functions assume that the environment variable $OSTYPE 
	is appropriately set, as is done automatically by the shell tcsh.  If it 
	is not set, the directory names collapse to the original values,
		$RHOME/bin/ and $RHOME/lib/
	To use them, create the approprate directories and place the correct 
	binaries therein. ( Note that the makefiles will not do this 
	automatically!)  Then replace $RHOME/bin/R and $RHOME/cmd/filename with 
	the modified ones.

----------------------------------------------------------------------
TASK:	Platform Independence
STATUS:	Open
FROM:	Friedrich.Leisch@ci.tuwien.ac.at
	IMHO we should definetely have platform-dirs for everything that's
	possibly platform-dependent ... resulting in something like
		<library>/<section>/<type>
	e.g. for R code and
		<library>/<section>/<type>/<platform>
	e.g. for exec and dynload-objects.
	for exec there's a problem though, as some exec's are
	shell/perl/whatever-scripts and *should* work on any platform
	...  

----------------------------------------------------------------------
TASK:	Changes to pt().
STATUS:	Closed
FROM:	<jlindsey@luc.ac.be>
	rhyper is probably using the same internal functions as for the
	Student t (pt) which has the same problem. I think the pbeta function is not
	calculating efficiently for large values.
	By the way, would it be possible to eliminate the line (floor) that
	rounds the degrees of freedom in pt.c? That way, pt can be used in
	likelihood functions for fitting the Student t distributions.

	What I did was to rewrite pt.c in R without the floor line and use it
	for building the Student t likelihood function in my nonlinear
	regression function, gnlr. What I find is that, as nlm searches, it gets
	slower and slower if the "degrees of freedom" parameter increases over
	about 8-10.
	  It seems to me that my son had another example with a comparison
	with S-Plus. I shall ask him.
	  Cheers, Jim


----------------------------------------------------------------------
TASK:	Seg Violation in "tapply"
STATUS:	Closed
FROM:	<Andreas.Weingessel@ci.tuwien.ac.at>
	Calling tapply with a NULL as INDEX argument causes a segmentation
	fault on an i-586-linux machine.
	So, if for example
		 y<-list(a=1:10,b=2:5)
	then
		tapply(y$a,y$c,mean)
	causes a segmentation fault. 
	This seg. fault is produced when a dimension of length integer(0) is
	assigned to a list with one element and this object is shown
	afterwards. E.g.:
	R>  y<-list(a=1:10)
	R> dim(y) <- integer(length(NULL))
	R> y
	Segmentation fault
	This happens in the code of tapply, when INDEX=NULL in the lines
	  extent <- integer(length(INDEX))
	and
	  dim(ans) <- extent

----------------------------------------------------------------------
TASK:	Poly
STATUS:	Open
FROM:	<Kurt.Hornik@ci.tuwien.ac.at>
	PS1.  There was also `poly' function in your snapshot WORK tree
	... do you already have a final version of that?

----------------------------------------------------------------------
TASK:	t Distribution
STATUS:	Open (check - may be closed)
FROM:	<thomas@biostat.washington.edu>
	Yes please.  Non-integer degrees of freedom are very useful for
	approximations as well. For example: Welch's unequal variance t-test,
	Sattherthwaite approximations in ANOVA, and others.
	If we can't get non-integer df we at least NEED a warning and preferably a
	mention in the help file. It seems that qt() and rt() handle non-integer
	df correctly (a relief, since I've been using them quite a bit) and that
	the chisq and f distributions are ok too.
	One simple solution is
		pt<-function(q,df) 1-0.5*(1-pf(q^2,1,df))
	using the fact that a t(n) is the square root of an F(1,n).

----------------------------------------------------------------------
TASK:	Vector Recycling Weirdness
STATUS:	Closed
FROM:	<thomas@biostat.washington.edu>
wompom:~> R
	R : Copyright 1997, Robert Gentleman and Ross Ihaka
	Version 0.49 Beta (April 23, 1997)
	R> f
	function () 
	{
		FALSE & matrix(FALSE, ncol = 1)
	}
	R> g
	function () 
	FALSE & matrix(FALSE, ncol = 1) 
	R> f()
	Warning in FALSE & matrix(FALSE, ncol = 1) : longer object length
		is not a multiple of shorter object length
	      [,1]
	[1,] FALSE
	R> g()
	      [,1]
	[1,] FALSE
	Is this weird or what?
	[ I can't remember what fixed this ... ]

----------------------------------------------------------------------
TASK:	"length" incompatibility
STATUS:	Closed
FROM:	<bates@auckland.ac.nz>
	In converting some S code that messes around with expressions and
	formulae and such I have found that
	 > mode((~ foo)[[2]])
	 [1] "symbol"
	 > length((~ foo)[[2]])
	 [1] NA
	I get a whole lot of code breaking on me because I check for the
	length of the object before looking at the mode.  I realize that
	symbols look different in R than in S (not to mention having a
	different name for the mode) but I'm not sure why the length of a
	symbol must be missing.  Is this an oversight?
	[ Symbols have length one now. ]

----------------------------------------------------------------------
TASK:	Yet another stupid way to cause a segfault:
STATUS:	Closed
FROM:	<hornik@ci.tuwien.ac.at>
	R> x
	Error: Object "x" not found
	R> debug(t.test)
	R> t.test(rnorm(10))
	debug: choices <- c("two.sided", "greater", "less")
	Browse[1]> return()
	NULL
	R> x
	Error: Object "x" not found
	Browse[1]> return()
	Segmentation fault
	[ It is now possible to return from browser() ]

----------------------------------------------------------------------
TASK:	Naming with Numeric Values and "unlist"
STATUS:	Open
FROM:	<hornik@ci.tuwien.ac.at>
	R> l <- list("11" = 1:5)
	R> l
	$11
	[1] 1 2 3 4 5
	R> unlist(l)
	111 112 113 114 115 
	  1   2   3   4   5 
	[ Bug or feature ? ]

----------------------------------------------------------------------
TASK:	all.names needed
STATUS:	Open
FROM:	<bates@stat.wisc.edu>
	I could not find the all.names function in R so I created the
	enclosed.  Comments, criticisms, or changes to a one-liner by creating
	nested anonymous functions are welcome.  I'll try to work out a
	corresponding all.vars function.

	### $Id: TASKS,v 1.30 1997/07/01 03:45:42 ihaka Exp $
	### Some replacement functions that are missing in R

	### Determine all the names (symbols) occuring in an object.
	### This is probably grossly inefficient.
	all.names <-
	  function (x) 
	{
	  if (mode(x) == "symbol") 
	    return(as.character(x))
	  if (length(x) == 0) 
	    return(NULL)
	  if (is.recursive(x)) 
	    return(unlist(lapply(as.list(x), all.names)))
	  character(0)
	}   

----------------------------------------------------------------------
TASK:	"sys.function" problem
STATUS:	Open
FROM:	<bates@stat.wisc.edu>
	I attempted to create a recursive anonymous function to be called
	within another function.  You may want to stop reading for a bit and
	consider how that would be done.  That is, how do you recursively call
	a function that has never been assigned a name?
	OK, you're back.  You probably came up with a better solution than I
	did but I used (sys.function())(arg) to do the recursion.  The piece
	of code looks like
	  flist <- (function(x) {
	    if (mode(x) == "call") {
	      if (x[[1]] == as.name("/")) 
		return(c(sys.function()(x[[2]]), sys.function()(x[[3]])))
	      if (x[[1]] == as.name("(")) 	# for R
		return(sys.function()(x[[2]]))
	    }
	    if (mode(x) == "(") return(sys.function()(x[[2]])) # for S
	    list(x)
	  })(getGroupsFormula(data, form, ...)[[2]])
	  ## I know it's horribly obscure.  Blame Bill Venables for teaching me this.
	Regretably, it doesn't work in R.  Using the debugger one finds that
	sys.function() returns the function being called the first time
	through but the second time through it returns NULL.  Is this a bug or
	a feature?

----------------------------------------------------------------------
TASK:	Matrix multiply problems
STATUS:	Open
FROM:	<thomas@biostat.washington.edu>
	Both of these used to work and seem useful and harmless:
	R> matrix(1,ncol=1)%*%c(1,2)
	Error in matrix(1, ncol = 1) %*% c(1, 2) : non-conformable arguments
	R> matrix(1,ncol=1)*(1:2)
	Error: dim<- length of dims do not match the length of object

----------------------------------------------------------------------
TASK:	"update" comments and fixes
STATUS:	Open
FROM:	<thomas@biostat.washington.edu>
	1. To make update() work with a new formula for glms, change the
	first line of the glm() function from
		call <- sys.call(
	to
		call<-match.call()
	(this means that the formula component of the returned call is
	labelled so that update can find it)

	2. update.lm doesn't do anything with its weights= argument
	Add
		if (!missing(weights))
			call$weights<-substitute(weights)
	Similarly, to get update to work properly on glms you need a lot
	more of these if statements (see update.glm at the end of the message).

	3. update.lm evaluates its arguments in the wrong frame.
	It creates a modified version of the original call and evaluates
	it in sys.frame(sys.parent()).  If update.lm is called directly
	this is correct, but if it is called via update() the correct
	frame is sys.frame(sys.parent(2)). Worse still, if it is called
	by NextMethod() from another update.foo() the correct frame is
	still higher up the list.

	My solution (a bit ugly) is to move up the list of enclosing calls
	checking at each stage to see if the call is NextMethod, update or an
	update method.  It can be seen at the end of update.glm at the bottom of
	this message, and something of this sort needs to be added to other update
	methods.

	update.glm<-function (glm.obj, formula, data, weights, subset,
		na.action, offset, family, x) 
	{
		call <- glm.obj$call
		if (!missing(formula)) 
			call$formula <- update.formula(call$formula, formula)
		if (!missing(data)) 
			call$data <- substitute(data)
		if (!missing(subset)) 
			call$subset <- substitute(subset)
		if (!missing(na.action)) 
			call$na.action <- substitute(na.action)
		if (!missing(weights)) 
			call$weights <- substitute(weights)
		if (!missing(offset)) 
			call$offset <- substitute(offset)
		if (!missing(family)) 
			call$family <- substitute(family)
		if (!missing(x)) 
			call$x <- substitute(x)
		notparent <- c("NextMethod", "update", methods(update))
		for (i in 1:(1+sys.parent())) {
			parent <- sys.call(-i)[[1]]
			if (is.null(parent))
				break	
			if (is.na(match(as.character(parent), notparent)))
				break
		}	
		eval(call, sys.frame(-i))
	}

----------------------------------------------------------------------
TASK:	Wisdom
STATUS:	Open
FROM:	<bates@stat.wisc.edu>
	Some of the "eternal truths" about the S language are:
	 - every object has a mode obtainable by mode(object)
	 - every object has a length obtainable by length(object)
	 - every object can be coerced to a list of the same length 
	One can imagine that code that messes around with functions and
	other expressions in R will break fairly quickly when these
	conditions do not hold.  I don't know how much work would be
	involved in patching over these differences between R and S
	but I suspect it would not be a trivial undertaking.

----------------------------------------------------------------------
TASK:	Hypergeometric probabilities
STATUS:	Closed.
FROM:	<maechler@stat.math.ethz.ch>
	I think that AS 152 (which has been improved, but is still
	available as file  ...statlib.../apstat/152 )
	should be used in place of  phyper.c
	[ I will look again, but I think my version is better! ]
	[ Well, at least when the typos are fixed :-)          ] 

----------------------------------------------------------------------
TASK:	"qt"
STATUS:	Open
FROM:	<p.dalgaard@kubism.ku.dk>
	> Kurt Hornik writes:
	>  > I found the following 2 problems (no debugging, sorry).
	>  > 
	>  > * qt(0.975, 3) never returns.
	>  > 
	>  > Can someone please check that?  Happens for me on Debian GNU/Linux/ix86
	>  > compiled with CFLAGS="-O2 -g".
	> 
	> I am having a look at the computations of p-values and quantiles which
	> depend on the incomplete beta function at  present. ....
	The original problem seems to be one of loss of accuracy with
	instruction reordering. Doubling the value of "acu" cures it (I ran it
	under the debugger and the test value was stuck at about 1.5e-32,
	being compared to acu=1e-32). This is probably a generic problem with
	these last-bit-accurate routines.

----------------------------------------------------------------------
TASK:	frametools
STATUS:	Open
FROM:	<p.dalgaard@kubism.ku.dk>
	The following three functions are designed to make manipulation of
	dataframes easier. I won't write detailed docs just now, but if you
	follow the example below, you should get the general picture. Comments
	are welcome, esp. re. naming conventions. 

	Note that these functions are definitely not portable to S because
	they rely on R's scoping rules. Not that difficult to fix, though: The
	nm vector and the "parsing" functions need to get assigned to
	(evaluation) frame 1 (the "expression frame" of S), and preferably
	removed at exit.

	data(airquality)
	aq<-airquality[1:10,]
	select.frame(aq,Ozone:Temp)
	subset.frame(aq,Ozone>20)
	modify.frame(aq,ratio=Ozone/Temp)

	Notice that in modify.frame(), any *new* variable must appear as a
	tag, not as the result of an assignment, i.e.:

	modify.frame(aq,Ozone<-log(Ozone)) works as expected
	modify.frame(aq,lOzone<-log(Ozone)) does not.

	This is mainly because it was tricky to figure out what part of a left
	hand side constitutes a new variable to be created (note that indexing
	could be involved). So assignments to non-existing variables just
	create them as local variables within the function. Making a virtue
	out of necessity, that might actually be considered a feature...

	----------------------------------------
	"select.frame" <-
	function (dfr, ...) 
	{
		subst.call <- function(e) {
			if (length(e) > 1) 
				for (i in 2:length(e)) e[[i]] <- subst.expr(e[[i]])
			e
		}
		subst.expr <- function(e) {
			if (is.call(e)) 
				subst.call(e)
			else match.expr(e)
		}
		match.expr <- function(e) {
			n <- match(as.character(e), nm)
			if (is.na(n)) 
				e
			else n
		}
		nm <- names(dfr)
		e <- substitute(c(...))
		dfr[, eval(subst.expr(e))]
	}
	"modify.frame" <-
	function (dfr, ...) 
	{
	        nm <- names(dfr)
	        e <- substitute(list(...))
	        if (length(e) < 2) 
	                return(dfr)
	        subst.call <- function(e) {
	                if (length(e) > 1) 
	                        for (i in 2:length(e)) e[[i]] <- subst.expr(e[[i]])
	                substitute(e)
	        }
	        subst.expr <- function(e) {
	                if (is.call(e)) 
	                        subst.call(e)
	                else match.expr(e)
	        }
	        match.expr <- function(e) {
	                if (is.na(n <- match(as.character(e), nm))) 
	                        if (is.atomic(e)) 
	                                e
	                        else substitute(e)
	                else substitute(dfr[, n])
	        }
	        tags <- names(as.list(e))
	        for (i in 2:length(e)) {
	                ee <- subst.expr(e[[i]])
	                r <- eval(ee)
	                if (!is.na(tags[i])) {
	                        if (is.na(n <- match(as.character(tags[i]), 
	                                nm))) {
	                                n <- length(nm) + 1
	                                dfr[[n]] <- numeric(nrow(dfr))
	                                names(dfr)[n] <- tags[i]
	                                nm <- names(dfr)
	                        }
	                        dfr[[tags[i]]][] <- r
	                }
	        }
	        dfr
	}
	"subset.frame" <-
	function (dfr, expr) 
	{
	        nm <- names(dfr)
	        e <- substitute(expr)
	        subst.call <- function(e) {
	                if (length(e) > 1) 
	                        for (i in 2:length(e)) e[[i]] <- subst.expr(e[[i]])
	                e
	        }
	        subst.expr <- function(e) {
	                if (is.call(e)) 
	                        subst.call(e)
	                else match.expr(e)
	        }
	        match.expr <- function(e) {
	                if (is.na(n <- match(as.character(e), nm))) 
	                        e
	                else dfr[, n]
	        }
	        r <- eval(subst.expr(e))
	        r <- r & !is.na(r)
	        dfr[r, ]
	}

----------------------------------------------------------------------
TASK:	General Problems
STATUS:	Open
FROM:	<jlindsey@luc.ac.be>
	1. A gentle reminder that the default has not been changed for saving
	.RData in batch mode (as was promised).
	2. The degrees of freedom for the null deviance in glm are wrong when
	some observations are weighted out. This can give silly answers, for
	example when applying anova. The number of weighted out observations
	should be subtracted, as in other df calculations.
	3. The null deviance itself is wrong in glm when an offset is used. It
	can be smaller than that when variables are added to the model!
	4. R gave a segmentation fault when I tried to fit a model with 49
	factor levels in glm (using R -v4). All these glm problems were with
	poisson.
	5. R still does not read my environmental variables to set memory
	size.
	Suggestions:
	1. d, p, q, and r functions for inverse Gauss and Laplace
	distributions.
	2. Add a fifth function for continuous distributions, the hazard
	function, h. For example, ht <- function(...) dt(...)/(1-pt(...))
	is the Student t hazard function.
	For writing likelihood functions, these would be much faster in C than
	R and some such as Weibull can be simplified.
	3. Add the five functions for three parameter distributions such as
	generalized F, extreme value, etc., Box-Cox,... (I have the densities,
	cumulative, and hazard as R functions.)
	4. Philippe Lambert and I have d and p functions working in R for the
	four-parameter stable family by inverting the characteristic function
	with a Fourier transform (requires C code). S-plus only has the r
	function for stables.

----------------------------------------------------------------------
TASK:	Complex Nits
STATUS:	Open
FROM:	Paul Gilbert <la-jassine@aix.pacwan.net>
	Mod, Re, Im, and Conj should work for Real numbers using as.complex
	complex should be
	   complex <- function (n = 0, real = numeric(), imaginary = numeric())
	not 
	   complex <- function (n = 0, real = numeric(), imag = numeric()) 

----------------------------------------------------------------------
TASK:	Generic Print
STATUS:	Open
FROM:	Paul Gilbert <la-jassine@aix.pacwan.net>
	I have  always thought that typing the name of an object generated
	a call to the print method for the object, however,  (in 0.49)
	I redefined the generic print method as 
		print <- function(x, ...)
		{if (is.tframe(x))  UseMethod("print.tframe")
		  else UseMethod("print")
		}
	Now I have an object z which returns TRUE to is.tframe(z) and
	> class(z)
	[1] "ts"     "tframe"
	Then
	> print(z)
	[1] 1981.50 2006.25    4.00
	But
	> z
	Error: comparison is possible only for vector types
	> traceback()
	[1] "c(\"print.ts(structure(c(1981.5, 2006.25, 4), class = c(\\\"ts\\\",
	\\\"tframe\\\"\", "
	[2] "c(\"print(structure(c(1981.5, 2006.25, 4), class = c(\\\"ts\\\",
	\\\"tframe\\\"\", "   
	This is generating a call to the class method print.ts
	rather than to print.tframe.ts as is done when I use
	print(z).  If my understanding that typing the name of an
	object should generate a call to the print method for the
	object then this is a bug. Otherwise, could someone please
	explain to me what it does. Thanks.

----------------------------------------------------------------------
TASK:	getenv()
STATUS:	Open
FROM:	Paul Gilbert <la-jassine@aix.pacwan.net>
	Here are two small problems I've pointed out before, but still
	seem to be in 0.49.
	1/ getenv() should return everything, not complain missing item.

----------------------------------------------------------------------
TASK:	summary.default
STATUS:	Open
FROM:	Paul Gilbert <la-jassine@aix.pacwan.net>
	2/ In summary.default
		 ...
			sumry[i, 2] <- if (is.object(ii)) 
				 class(ii)
	should be changed to
		...
			sumry[i, 2] <- if (is.object(ii)) 
				paste(class(ii), collapse=" ")
	so that it works with lists of lists. (This fix was suppose to be
	added to Splus 4.)

----------------------------------------------------------------------
TASK:	Time Series Problems
STATUS:	Open
FROM:	<la-jassine@aix.pacwan.net>
	Here are four problems with ts:
	1/  ts matrix subscripting should support drop=F:
	> z<- matrix(1:10,5,2)
	> z <-ts(z)
	> z[,1,drop=F]
	Error in [.ts(z, , 1, drop = F) : unused argument to function

	2/  == and other comparisons with non-ts matrices should work:
	> z <- matrix( 1:10,5,2)
	> ts(z)
	Time-Series:
	Start = c(1, 1) 
	End = c(5, 1) 
	Frequency = 1 
	     [,1] [,2]
	[1,]    1    6
	[2,]    2    7
	[3,]    3    8
	[4,]    4    9
	[5,]    5   10
	> z == ts(z)
	Error: invalid time series parameters specified

	3/ The generic functions start and end need default methods to return a
	result for matrices as previously and in S. The following seems to work.

	start.default <- function (x) start(ts(x))
	end.default   <- function (x)   end(ts(x))

	4/ In the function start.ts (and in end.ts) ts[1] in the last line
	is not defined. Perhaps I am missing something?
	start.ts
	function (x) 
	{
		ts.eps <- .Options$ts.eps
		if (is.null(ts.eps)) 
			ts.eps <- 1e-06
		tsp <- attr(as.ts(x), "tsp")
		is <- tsp[1] * tsp[3]
		if (abs(is - round(is)) < ts.eps) {
			is <- floor(tsp[1])
			fs <- floor(tsp[3] * (tsp[1] - is) + 0.001)
			c(is, fs + 1)
		}
		else ts[1]
	}
 

----------------------------------------------------------------------
TASK:	Recycling problems
STATUS:	Open
FROM:	Paul Gilbert <la-jassine@aix.pacwan.net>
	In R 0.49 comparison of logic matrices with & and | seems
	to sometimes generate false warning messages about longer
	object length is not a multiple of shorter object length.
	I have not been able to isolate the exact circumstances.

----------------------------------------------------------------------
TASK:	Generic "write" function
STATUS:	Open
FROM:	<Kurt.Hornik@ci.tuwien.ac.at>
	Following my posting of a write.table() function, Martin
	suggested that one could have a generic write() function
	and special methods for e.g. time series, data frames, etc.
	Well, a month has passed since ...
	What does everyone think?  Is it a good idea, or would
	write.table() be enough?  If we think that it is not enough,
	which arguments should the write methods typically allow?
	What about
	write.xxx (x,		# object
		   file =       # filename, default stdout
                   append =     # obvious
                   sep =	# obvious
		   eol =        # end of line char
                   ...)
	???
	On the other hand, it seems clear that something like
	write.table() is nice, and what it should do.  But what
	about classes other than data.frame?

	Note that S has a  write(.)  function  which would be our
		write.default(.)
	your	write.table	    would be our 
		write.data.frame
	The only addition would be a  'write.matrix' which would be 'like'
	write.data.frame, the only problem being that  'matrix' is not a class
	(yet).
		[Note that in S4, everything has a class; 
	I'm voting for matrices to have a class in R  ..]
	write.default  could 'despatch' to write.matrix if  x  is a matrix.


----------------------------------------------------------------------
TASK:	ls.print problem
STATUS:	Open
FROM:	<VENKAT@biosta.mskcc.org>
	ls.print produces error that I don't seem to be able to trace.
	Output of the commands as follows: (hyeung is a 24x2 matrix of data)

	> summary(hyeung)
	       x.1             x.2
	 Min.   : 28.0   Min.   : 10.0
	 1st Qu.: 72.0   1st Qu.: 87.5
	 Median : 86.5   Median : 92.5
	 Mean   : 81.0   Mean   : 82.5
	 3rd Qu.: 97.0   3rd Qu.:100.0
	 Max.   :100.0   Max.   :100.0
	> summary(lsfit(hyeung[,1],hyeung[,2]))
		  Length Class  Mode
	coef       2     -none- numeric
	residuals 24     -none- numeric
	intercept  1     -none- logical
	qr         6     -none- list
	> ls.print(lsfit(hyeung[,1],hyeung[,2]))
	trace: ls.print(lsfit(hyeung[, 1], hyeung[, 2]))
	Error: missing value in ``n1 : n2''

	Kurt Hornik found:
	The problem seems to be that

		ncol(ls.out$residuals)

	gives NULL if ls.out is a vector.  An easy fix is to replace each
	occurrence of ncol in ls.print() by NCOL.

	A patch is appended below.

	Btw, my help file for NCOL comes up with `.COL' rather than `NCOL'.  Can
	anyone verify that?

*** src/library/base/funs/lsfit.orig	Tue May 13 07:54:24 1997
--- src/library/base/funs/lsfit	Tue May 13 07:51:19 1997
*************** ls.print <- function(ls.out, digits=4, p
*** 256,265 ****
  
  	# construct coef table
  
! 	coef.table <- as.list(1:ncol(ls.out$residuals))
! 	if(ncol(ls.out$residuals)==1) coef <- matrix(ls.out$coef, nc=1)
  	else coef <- ls.out$coef
! 	for(i in 1:ncol(ls.out$residuals)) {
  		covmat <- (resss[i]/(n[i]-p)) * (qrinv%*%t(qrinv))
  		coef.table[[i]] <- cbind(coef[, i], diag(covmat)^.5,
  			coef[, i]/diag(covmat)^.5,
--- 256,265 ----
  
  	# construct coef table
  
! 	coef.table <- as.list(1:NCOL(ls.out$residuals))
! 	if(NCOL(ls.out$residuals)==1) coef <- matrix(ls.out$coef, nc=1)
  	else coef <- ls.out$coef
! 	for(i in 1:NCOL(ls.out$residuals)) {
  		covmat <- (resss[i]/(n[i]-p)) * (qrinv%*%t(qrinv))
  		coef.table[[i]] <- cbind(coef[, i], diag(covmat)^.5,
  			coef[, i]/diag(covmat)^.5,
*************** ls.print <- function(ls.out, digits=4, p
*** 270,276 ****
  		#print results
  
  		if(print.it) {
! 			if(ncol(ls.out$residuals)>1)
  				cat("Response:", colnames(ls.out$residuals)[i],
  				"\n\n")
  			cat(paste("Residual Standard Error=", format(round(
--- 270,276 ----
  		#print results
  
  		if(print.it) {
! 			if(NCOL(ls.out$residuals)>1)
  				cat("Response:", colnames(ls.out$residuals)[i],
  				"\n\n")
  			cat(paste("Residual Standard Error=", format(round(

----------------------------------------------------------------------
TASK:	ls.print
STATUS:	Open
FROM:	<maechler@stat.math.ethz.ch>
	Yes, I do confirm that the  Help page  (?NCOL) contains  '.COL'.
	Apply the following patch (to doc2ms) in  $RHOME/etc , and "all is well":

--- doc2ms	Tue May 13 10:10:33 1997
+++ Old/doc2ms	Sun Nov 24 23:41:49 1996
@@ -122,8 +122,6 @@
 $2
 .DE
 ')
-define(DEQTEX,`')
-define(DEQHTML,`')
 END
 # Fix up the input to protect things that m4 is sensitive about.
 sed '
@@ -149,8 +147,8 @@
 s/M4_RQ/'\''/g
 s/M4_COMMA/,/g
 s/M4_IFELSE/ifelse/g
-s/^\.Internal/\\\&.Internal/
-s/^\.C/\\\&.C/
-s/^\.Fortran/\\\&.Fortran/
+s/^.Internal/\\\&.Internal/
+s/^.C/\\\&.C/
+s/^.Fortran/\\\&.Fortran/
 s/\\n/\\\\n/g
 '
----------------------------------------------------------------------
TASK:	dhyper
STATUS:	Closed
FROM:	<VENKAT@biosta.mskcc.org>
	I get the following incorrect answer
	   > dhyper(34,410,312,49)
	   [1] 2.244973e-118
	when the correct value is
	   > dhyper(34,410,312,49)          (from S-Plus)
	   [1] 0.0218911
	[ Caused by a typo in "math4" (arithmetic.c)    ]
	[ The 3rd argument was used instead of the 4th. ]

----------------------------------------------------------------------
TASK:	Comparison with NA and Zero-Length Vectors
STATUS:	Open
FROM:	<thomas@biostat.washington.edu> + <maechler@stat.math.ethz.ch>
	Thomas: Any comparison with NULL generates an error
	Error: comparison is possible only for vector types
	whereas in S(-PLUS) it gives NA, which seems more sensible.
	Along similar lines, comparison with a length 0 vector
	returns logical(0) in R but NA in S.

	Martin: Isn't  logical(0)  more  logical than  NA ?
	I agree that it would be best  (convenience)
	if   'NULL==1' returned the same as 'numeric(0)==1'.
	At the moment, I don't see why compatibility with S should be
	important here:
		if( NULL == anything)  
	or, e.g.,	if( numeric(0) == numeric(0) )
	give an error anyway, i.e., you have to test for length 0 _anyway_
	in the cases where one comparison argument may have zero length.

	Thomas: I didn't (previously) make any comment on this --
	I only said that NA was more logical than an error message.
	However, the advantage of returning NA is that NA | TRUE
	is TRUE, NA & FALSE is FALSE, which doesn't happen with
	logical(0). Also, from a compatibility point of view one
	of them is tested with is.na(), the other with length(),
	so it can matter which one you use.  Of course no-one should
	deliberately write code where it matters, but these things
	happen.
	It seems in fact that logical(0) | TRUE causes R to freeze
	(R0.49, sparc solaris).
	Robert: Well, we thought
	  logical(0) & T should return logical(0)
	  logical(0) | T should return logical(0)
	already we have NA | T returns T and  NA & T returns NA

----------------------------------------------------------------------
TASK:	Modules
STATUS:	Open
FROM:	<luke@stat.umn.edu>
	I came across a paper on scheme module design that may be
	under consideration for rnrs -- I'm a bit hazy on that. At
	any rate, it is at http://www.cs.princeton.edu/~blume/modules.dvi.
	I haven't read it carefully yet, but it is fairly heavily
	influenced by SML but doesn't go too far overboard (well
	maybe a bit).

----------------------------------------------------------------------
May 1.
----------------------------------------------------------------------
TASK:	"eigen"
STATUS:	Closed
FROM:	<p.dalgaard@kubism.ku.dk>
	eigen() seems to work for symmetric matrices only. This is out
	of sync with the help file.

	Paul Gilbert <la-jassine@aix.pacwan.net>:
	As Peter Dalgaard mentioned, eigen does not yet support
	non-symmetric matrices.  This is confirmed by looking at
	eigen.c, which also seems to suggest a different source
	for the code than is indicated in the help.
	The help also indicates an optional argument "symmetric"
	which is not in the code.  As I recall, the Splus version
	calls two different  C code algorithms for symmetric and
	non-symmetric matrices. The argument is useful to insure
	continuity when that is an issue.
	If you don't  have C or fortran code handy, I have fortran
	from the LAPACK library which I used before Splus supported
	non-symmetric matrices. I would have to get someone to send
	it from work, but I think that is possible.  Please let me
	know if you want be to try to do this.

----------------------------------------------------------------------
TASK:	"abline" incompatibility
STATUS:	Open
FROM:	<nobu@psrc.isac.co.jp>
	I found a little different behavior of R with S.
	at R-0.49:
	    > a
	    [1] 12 23 22 34 44 54 55 70 78
	    > plot(a)
	    > abline(lsfit(seq(1,len=length(a)), a))
	    Error: no applicable method for "coefficients"
	at S (from AT&T '92) result draw coefficient line without error.
	Then I think to need define a function as followed:
	    coefficients.default <- function(x) x$coef

----------------------------------------------------------------------
TASK:	Legend problems
STATUS:	Open
FROM:	<jlindsey@luc.ac.be>
	When legend is used, the box around it has the line-type
	of the last call to lines or plot instead of solid always.

----------------------------------------------------------------------
TASK:	Curses for Linux
STATUS:	Closed
FROM:	<agebhard@zidsrv.sci.uni-klu.ac.at>
	When I tried to compile R on a S.u.S.E-4.4 linux box, I ended up with
	unresolved symbols from libtermcap. So I decided to use the newer libncurses.

	Applying the following patch to configure.in and creating a new
	configure script with "autoconf  configure.in > configure" solved my problems.

	--- configure.in.orig   Tue May  6 15:05:20 1997
	+++ configure.in        Tue May  6 15:05:23 1997
	@@ -142,13 +142,17 @@
 
	 #  LIBRARIES
	 #
	-#  This is set up so we only get one of one of -ltermcap and -ltermlib
	+#  This is set up so we only get one of one of -lncurses -ltermcap and -ltermlib
 
	 AC_CHECK_LIB(m, sin)
	+AC_CHECK_LIB(ncurses, main)
	+if test -z "HAVE_LIBNCURSES"
	+then
	 AC_CHECK_LIB(termcap, main)
	 if test -z "HAVE_LIBTERMCAP"
	 then
	 AC_CHECK_LIB(termlib, main)
	+fi
	 fi
	 AC_CHECK_LIB(readline, main)
	 AC_CHECK_LIB(dl, dlopen)
	[ Changes made. Needs testing by Linuxers. ]

----------------------------------------------------------------------
TASK:	"rnorm" change
STATUS:	Open
FROM:	Paul Gilbert <la-jassine@aix.pacwan.net>
	For some reason I cannot determine, the function rnorm
	seems to be returning different values in R 0.49 than it
	did in R 0.16.1 (in Linux ELF). The function runif is
	unchanged.
	[  I believe I changed the underlying generator.       ]
	[  I was worried about behavior in the extreme tails.  ]
	[  Should we change back again?                        ]

----------------------------------------------------------------------
TASK:	"formula" problems
STATUS:	Open
FROM:	 <mikem@stat.cmu.edu>
	Several bugs (no solutions, yet).  These might be well known.
	1) If one does, e.g.,  mymod <- lm(y ~ x); formula(mymod)
	then one does not get back the formula (one gets,
	Error: invalid formula) 
	2) if x is of mode numeric, then the model formula
		mymod <- lm(y ~ x + x^2)
	is not processed as S would do it.    The model is fit
	ignoring the x^2 term, however mymod$call includes the x^2
	term.  This seems to be a bug (or maybe feature) in applying
	model formulae operators to numeric quantities.  I expect
	(from experience with S) that x^2 will be interpreted as
	a math operator.  Whatever the right thing to do is, it
	needs to be documented.

----------------------------------------------------------------------
TASK:	formula problems
STATUS:	Open
FROM:	<p.dalgaard@kubism.ku.dk>
	Mike Meyer <mikem@stat.cmu.edu> writes:
	> Several bugs (no solutions, yet).  These might be well known.
	> 1) If one does, e.g.,  mymod <- lm(y ~ x); formula(mymod)
	> then one does not get back the formula (one gets, Error: invalid formula) 
	Yep. Seems that we need a
	formula.lm<-function(x)formula(x$terms)
	> 2) if x is of mode numeric, then the model formula
	> 	mymod <- lm(y ~ x + x^2)
	> is not processed as S would do it. The model is fit ignoring the x^2 term, 
	We had that topic a while back. I think it was concluded
	that it is a feature, because mixing model formulas and
	arithmetic ditto is bad practice. (I don't have any strong
	feeling about this, personally. As long as R won't introduce
	those awful Helmert contrasts as default...)

----------------------------------------------------------------------
TASK:	formula problems
STATUS:	Open
FROM:	<wvenable@attunga.stats.adelaide.edu.au>
	Peter Dalgaard writes:
	 > > 
	 > > 2) if x is of mode numeric, then the model formula
	 > > mymod <- lm(y ~ x + x^2)
	 > > is not processed as S would do it.  The model is fit[ted]
	 > > ignoring the x^2 term...
	 > 
	 > We had that topic a while back.  I think it was concluded that
	 > it is a feature, because mixing model formulas and arithmetic
	 > ditto is bad practice.
	I don't recall we did, but in any case I'd like to re-open it.

	There is an anomaly in the way : and ^ terms are handled in the
	sense that the logical and useful thing is obvious but does not
	happen.  Let me give an example.  Suppose a and b are factors, x
	and y are not.

	A term such as (a + b + x + y)^2 should be expanded out binomial
	fashion, coefficients stripped away and the remaining products
	treated as : products.  Then S copes with terms like a:a, a:b and
	a:x fine, even x:y is handled by having it generate a column of
	xy-products, as it should.

	But a term such as x:x does not generate a column of x-squares,
	it is merely removed as it would be if it were a factor.  This is
	a complete anomaly, and one that I don't think would be hard or
	dangerous for R to rectify.  Indeed it would be very useful to
	generate a complete second degree regression in three variables
	using y ~ (1 + x1 + x2 + x3)^2.  As it is now it generates linear
	and product terms only and omits the powers.  Go figure.

	 > (I don't have any strong feeling about this, personally.  As
	 > long as R won't introduce those awful Helmert contrasts as
	 > default...)

	Ah, the Helmert contrasts b\^ete noir.  For ANOVA the contrast
	matrix used is mostly irrelevant.  For regression models I agree,
	treatment contrasts would be generally more easily interpreted.

	I presume the reason they were used at all is because if you have
	equal replication of everything the Helmert contrasts give you a
	model matrix with orthogonal columns, so all estimates are
	uncorrelated.  Whenever do you get equal replication, though?

----------------------------------------------------------------------
TASK:	formula problems
STATUS:	Open
FROM:	<p.dalgaard@kubism.ku.dk>
	Bill Venables <wvenable@attunga.stats.adelaide.edu.au> writes:
	> A term such as (a + b + x + y)^2 should be expanded out binomial
	> fashion, coefficients stripped away and the remaining products
	> treated as : products.  Then S copes with terms like a:a, a:b and
	> a:x fine, even x:y is handled by having it generate a column of
	> xy-products, as it should.
	I tend to agree.
	> Ah, the Helmert contrasts b\^ete noir.  For ANOVA the contrast
	> matrix used is mostly irrelevant.  For regression models I agree,
	> treatment contrasts would be generally more easily interpreted.
	Understatement of the year... Last time I bumped into them, it took me
	and a colleague more than an hour to figure out how to interpret the
	regression coefficients, and, I may add, the solution was *not* what
	the white book said it was (it's not just one level minus the average
	of the preceding, the parameter is also scaled by the reciprocal of
	the level number). [There's a split-second solution -- see below --
	but we sort of didn't think of it at the time...] 
	> I presume the reason they were used at all is because if you have
	> equal replication of everything the Helmert contrasts give you a
	> model matrix with orthogonal columns, so all estimates are
	> uncorrelated.  Whenever do you get equal replication, though?
	Hardly ever. Actually, I though that the point was not so much
	ortogonality, but the successive testing (A=B, A=B=C, A=B=C=D,...).
	However that is just plainly wrong outside of balanced ANOVA's.
	And, even in that case, once the first two levels differ, the rest
	of the coefficients lose all meaning.

----------------------------------------------------------------------
TASK:	formula problems
STATUS:	Open
FROM:	<thomas@biostat.washington.edu>
	We also need to fix formula.default. At the moment it only
	looks for x$formula.  Other standard places to keep a
	formula are x$call$formula and x$terms.  How about

	formula.default<-function (x)
	{
		if (!is.null(x$formula))
			return(eval(x$formula))
		if (!is.null(x$call$formula))
			return(eval(x$call$formula))
		if (!is.null(x$terms))
			return(x$terms)
		switch(typeof(x), NULL = structure(NULL, class = "formula"),
			character = formula(eval(parse(text = x)[[1]])),
			call = eval(x), stop("invalid formula"))
	}
	One disdvantage to extracting the formula from $terms
	instead of $call$formula is that in S a terms object is
	not a formula. On the other hand it doesn't really matter
	as long as people use the formula() function.

----------------------------------------------------------------------
TASK:	formula problems
STATUS:	Open
FROM:	<wvenable@attunga.stats.adelaide.edu.au>
	Peter Dalgaard writes:
	 > Bill Venables <wvenable@attunga.stats.adelaide.edu.au> writes:
	 > > Ah, the Helmert contrasts b\^ete noir.  For ANOVA the contrast
	 > > matrix used is mostly irrelevant.  For regression models I agree,
	 > > treatment contrasts would be generally more easily interpreted.
	 > Understatement of the year... Last time I bumped into them, it took me
	 > and a colleague more than an hour to figure out how to interpret the
	 > regression coefficients, and, I may add, the solution was *not* what
	 > the white book said it was (it's not just one level minus the average
	 > of the preceding, the parameter is also scaled by the reciprocal of
	 > the level number). [There's a split-second solution -- see below --
	 > but we sort of didn't think of it at the time...] 

	A few weeks ago I gave a fairly detailed discussion of how to
	relate contrast matrices and their interpretation in s-news.  I
	could re-issue it or post it to people if that was their wish.

	There is also to be an extended discussion of the subject in V&R2
	due out in July, with a further elaboration to appear (real soon
	now...) in the online complements.

	 > > I presume the reason they were used at all is because if you have
	 > > equal replication of everything the Helmert contrasts give you a
	 > > model matrix with orthogonal columns, so all estimates are
	 > > uncorrelated.  Whenever do you get equal replication, though?
	 > 
	 > Hardly ever. Actually, I though that the point was not so much
	 > ortogonality, but the successive testing (A=B, A=B=C, A=B=C=D,...).
	 > However that is just plainly wrong outside of balanced ANOVA's.
	 > And, even in that case, once the first two levels differ, the rest
	 > of the coefficients lose all meaning.

	Indeed.  That's why I tended to discount that possibility myself.
	Here is a contrast matrix generator I sometimes prefer to use
	that corresponds to testing A=B, B=C, C=D, ...  Of course the
	contrasts are not mutually orthogonal.  How it works is left as a
	little puzzle.  (This function works in S.  I haven't tested it
	in R, but it should work if lower.tri() is available.)

	contr.sdif <- function(n, contrasts = T)
	{
	# contrasts generator giving `successive difference' contrasts.
	  if(is.numeric(n) && length(n) == 1) {
	    if(n %% 1 || n < 2)
	      stop("invalid number of levels")
	    lab <- as.character(seq(n))
	  }
	  else {
	    lab <- as.character(n)
	    n <- length(n)
	    if(n < 2)
	      stop("invalid number of levels")
	  }
	  if(contrasts) {
	    contr <- col(matrix(nrow = n, ncol = n - 1))
	    upper.tri <- !lower.tri(contr)
	    contr[upper.tri] <- contr[upper.tri] - n
	    structure(contr/n, dimnames = list(lab, paste(
	      lab[-1], lab[ - n], sep = "-")))
	  }
	  else structure(diag(n), dimnames = list(lab, lab))
	}
	> contr.sdif(4)
	    2-1  3-2   4-3 
	1 -0.75 -0.5 -0.25
	2  0.25 -0.5 -0.25
	3  0.25  0.5 -0.25
	4  0.25  0.5  0.75

----------------------------------------------------------------------
TASK:	plot line textures
STATUS:	Closed
FROM:	<jlindsey@luc.ac.be>
	When lines are plotted using a lot of points (say 250),
	all types look solid except the dotted (3) on the screen.
	Postscript output for the same plot instruction is correct.
	[ I think we're stuck with this.  Its what X delivers. ]

----------------------------------------------------------------------
TASK:	solve bug
STATUS:	Closed
FROM:	<p.dalgaard@kubism.ku.dk>
	> solve(cbind(c(1,1,1,1),contr.helmert(4)))
		    [,1]        [,2]          [,3]         [,4]
	[1,]  0.25000000  0.25000000  2.500000e-01 2.500000e-01
	[2,] -0.50000000  0.50000000  1.850493e-17 1.850493e-17
	[3,] -0.16666667 -0.16666667  3.333333e-01 1.117072e-17
	[4,] -0.08333333 -0.08333333 -8.333333e-02 2.500000e-01
	> solve(cbind(c(1,1,1,1),contr.helmert(4)))
	Error: incorrect tag type
	solve(cbind(c(1,1,1,1),contr.helmert(4)))
			 ^
	Error: syntax error
	[ Already fixed by Robert I think. ]

----------------------------------------------------------------------
TASK:	memory error?
STATUS:	Closed?
FROM:	<thomas@biostat.washington.edu>
	I have a probably related problem. Sporadically, an attempt to do
		a[,1,1,drop=F]
	or similar subsetting on a 3-d matrix causes a segfault at
	line 83 of attrib.c.  In a previous version this happened
	reliably when dimensions were lost from multi-d arrays and
	was due to incorrect handling of the dimnames attributes
	which crashed attrib.c at that point when the dimnames were
	accessed.
	Is the same sort of thing happening again?
	[ I have been unable to reproduce this. ]

----------------------------------------------------------------------
TASK:	startup processing
STATUS:	Open
FROM:	<mikem@stat.cmu.edu>
	1) The .RData file (and S .Data area) are cputype dependent.
	When R is used from different types of machines (say, HP
	and Sun) that share a common filesystem (say afs or dfs)
	then loading the wrong type of .RData file can lead to
	mysterious behaviour.   In my environment, undergraduate
	students are the most likely to log into different cputypes,
	and they end up being quite confused.   To solve this
	problem in S I set up an S_WORK environment variable that
	set the name of the .Data area, via the front end shell
	script.  For example, on the HP I use .Data.hp.   I would
	like to see the same facility in R.  if R_WORK is missing,
	then use the standard name.  If R_WORK exists, then use
	that name as the file to save the R session in.  (Maybe
	S_WORK exists in Splus only to please me, but it is useful :-).
	2) Again, along the lines of something that S does that is
	actually useful.  In S you can set the S_FIRST environment
	variable and have this used as the equivalent of the R
	.Rprofile file.   Might it be a good idea to allow an
	R_FIRST environment variable as well.  That way I could
	set user specific preferences that apply no matter what
	directory I have working in.

----------------------------------------------------------------------
TASK:	Machine independence
STATUS:	Closed?
FROM:	<luke@stat.umn.edu>
	An alternative that may be worth considering is to make
	.Rdata machine independent, perhaps by using the xdr routines
	-- I think these are available on Mac and Windows as well
	as any unix system that does nfs.

	If a move toward machine-independent representation seems
	reasonable, it may be worth looking at some of the binary
	data exchange formats used by nasa and others,

		CDF http://nssdc.gsfc.nasa.gov/cdf/cdf_home.html
		netCDF http://www.unidata.ucar.edu/packages/netcdf/index.html
		HDF http://hdf.ncsa.uiuc.edu/

	There may also be something useful in the "Scientific Data Format
	Information FAQ"
	(http://www.cv.nrao.edu/fits/traffic/scidataformats/faq.html).
	[  I have make save and load use the xdr library when it is  ]
	[  available.  It would be nice to have the xdr code on all  ]
	[  platforms.  Not too hard ...  ]

----------------------------------------------------------------------
TASK:	Function Argument Naming
STATUS:	Open
FROM:	<maechler@stat.math.ethz.ch>
	There is a problem with  'default argument evaluation'
	when I use an existing function name as argument name :

	sintest <- function(x, y = 2, sin= sin(pi/4))
	{
	  ## Purpose: Test of   "default argument evaluation"
	  ## -------- Fails for  R-0.49.  Martin Maechler, Date:  9 May 97.
	  c(x=x, y=y, sin=sin)
	}

	## R-0.49:
	R> sintest(1)
	##> Error in sintest(1) : recursive default argument reference

	## S-plus 3.4  (being 100% ok):
	S> sintest(1)
	  x y       sin 
	  1 2 0.7071068
	 Warning messages:
	   looking for function "sin", ignored local non-function in: sintest(1)

	-------------------------------------------------------
	The following shows bugs, both in R and S:

	sintest2 <- function(x ,y = 2)
	{
	  ## Purpose: Test of   "default argument evaluation"
	  ## -------- Fails for  S-plus 3.4.  Martin Maechler, Date:  9 May 97.
	  c(x=x, y=y, sin=sin)
	}

	R> sintest2(1)
	[[1]]
	[1] 1

	[[2]]
	[1] 2

	[[3]]
	<primitive: sin>

	--------------- is almost okay, 
			the buglet being that the names have been dropped from the list.

	But watch this:
	S> sintest2(1)
	function(x = 1, y = 2, sin.x)
	sin2 = .Internal(sin(x), "do_math", T, 109)

	--- returning a function 

		((now we see, why S's way of treating functions as
		  lists sometimes badly sucks)).

----------------------------------------------------------------------
TASK:	Function argument naming
STATUS:	Open
FROM:	<luke@stat.umn.edu>
	Martin Maechler wrote:
	[ Stuff above. ]

	For better or worse, S and R allow default expressions to
	contain references variables that are (or rather may be)
	created in the function body, so (in R and Splus)

	> x<-1
	> f<-function(a,b=x) { if (a) x<-2; b}
	> f()
	Error: Argument "a" is missing, with no default
	> f(T)
	[1] 2
	> f(F)
	[1] 1

	More traditional lexical scoping would make the reference
	to x in the default always be global, but lots of code
	would break. I think we're stuck with this behavior as a
	corollary to the way S wants default arguments to work.

	Actually S is a bit inconsistent in its error message --
	if you have a non-function argument it gives the same
	message as R,

	> g<-function(x=x) x
	>g()
	Error in g(): Recursive occurrence of default argument "x"
	Dumped

	Also in R's lexical scoping you probably do want the argument
	name to shadow any outer definitions if you want to be able
	to define default arguments that are recursive functions,
	e.g.

	> g<-function(n, nfac=function(x) {
		if (x <= 1) 1 else nfac(x-1)*x }) nfac(n);
	> g(6)
	[1] 720

----------------------------------------------------------------------
TASK:	plot axis & log
STATUS:	Open
FROM:	<kovac@figaro.stats.bris.ac.uk>
	The following commands crash:
	> plot(1:4,axes=F,log="x")
	> axis(1,c(1,2,3,4))
	zsh: segmentation fault  R
	Lines 35-37 of axis():
	35:        else {
	36:                ind <- (usr[1] <= at & at <= usr[2])
	37:        }
	should be replaced by
		else {
			if (log)
				ind <- (10^usr[1] <= at & at <= 10^usr[2])
			else ind <- (usr[1] <= at & at <= usr[2])
		}
	Moreover, there should be a check if length(at) equals zero
	before calling the internal axis command.
	But wait, there's more:
	> plot(1:4,log="x")
	> plot(1:4)
	The second call of plot produces an empty plot. The following
	sequence works:
	> plot(1:4,log="x")
	> par(xlog=F)
	> plot(1:4)        
	Why does R have the graphical parameters "xlog" and "ylog"?
	They do not seem to work for me and are not used by S-Plus.

----------------------------------------------------------------------
TASK:	axis problems
STATUS:	Open
FROM:	<kovac@figaro.stats.bris.ac.uk>
	The commands
	> plot(1:4,axes=F)
	> axis(1,c(4,3,2,1))
	produce the tick-marks but not the labels (except the last
	one). Sorting the vector at in axis() seems to work, ie
	should lines 35-40 should read:
		else {
			at <- sort(at)
			if (log)
				ind <- (10^usr[1] <= at & at <= 10^usr[2])
			else ind <- (usr[1] <= at & at <= usr[2])
		}

----------------------------------------------------------------------
TASK:	axis problems
STATUS:	Open
FROM:	<kovac@figaro.stats.bris.ac.uk>
	Here are another three problems with logarithmic scales:
	1) segments() does not work with logarithmic scales. I suggest to change
	lines 962-973 in "plot.c":

	    for (i = 0; i < n; i++) {
		if (FINITE(xt(x0[i%nx0])) && FINITE(yt(y0[i%ny0]))
		    && FINITE(xt(x1[i%nx1])) && FINITE(yt(y1[i%ny1]))) {
		    GP->col = INTEGER(col)[i % ncol];
		    if(GP->col == NA_INTEGER) GP->col = colsave;
		    GP->lty = INTEGER(lty)[i % nlty];
		    GStartPath();
		    GMoveTo(XMAP(xt(x0[i % nx0])), YMAP(yt(y0[i % ny0])));
		    GLineTo(XMAP(xt(x1[i % nx1])), YMAP(yt(y1[i % ny1])));
		    GEndPath();
		}
	    }

	2) rect() does not work either. Unfortunately, do_rect() in "plot.c" 
	overrides the yt() function... What about this (lines 983-1031):

	SEXP do_rect(SEXP call, SEXP op, SEXP args, SEXP env)
	{
	    SEXP sxl, sxr, syb, sys, col, lty, border;
	    double *xl, *xr, *yb, *ys;
	    int i, n, nxl, nxr, nyb, nys;
	    int ncol, nlty, nborder;
	    int colsave, ltysave;

	    GCheckState();

	    if(length(args) < 4) errorcall(call, "too few arguments\n");
	    xypoints(call, args, &n);

	    sxl = CAR(args); nxl = length(sxl); args = CDR(args);
	    syb = CAR(args); nyb = length(syb); args = CDR(args);
	    sxr = CAR(args); nxr = length(sxr); args = CDR(args);
	    sys = CAR(args); nys = length(sys); args = CDR(args);

	    PROTECT(col = FixupCol(GetPar("col", args)));
	    ncol = LENGTH(col);

	    PROTECT(border =  FixupCol(GetPar("border", args)));
	    nborder = LENGTH(border);

	    PROTECT(lty = FixupLty(GetPar("lty", args)));
	    nlty = length(lty);

	    xl = REAL(sxl);
	    xr = REAL(sxr);
	    yb = REAL(syb);
	    ys = REAL(sys);

	    ltysave = GP->lty;
	    colsave = GP->col;
	    GMode(1);
	    for (i = 0; i < n; i++) {
		if (FINITE(xt(xl[i%nxl])) && FINITE(yt(yb[i%nyb]))
		    && FINITE(xt(xr[i%nxr])) && FINITE(yt(ys[i%nys])))
			GRect(XMAP(xt(xl[i % nxl])), YMAP(yt(yb[i % nyb])),
			      XMAP(xt(xr[i % nxr])), YMAP(yt(ys[i % nys])),
			    INTEGER(col)[i % ncol],
			    INTEGER(border)[i % nborder]);
	    }
	    GMode(0);
	    GP->col = colsave;
	    GP->lty = ltysave;
	    UNPROTECT(3);
	    return R_NilValue;
	}

	3) The legend() function needs changes as well. I attach my
	quick hack below, but I think there are better solutions... :-)

	legend <-
	function (x, y, legend, fill, col = "black", lty, pch, bty = "o", 
		bg = par("bg"), xjust = 0, yjust = 1, ...) 
	{
		xlog <- par("xlog")
		ylog <- par("ylog")
		if (xlog) 
			x <- log10(x)
		if (ylog) 
			y <- log10(y)
		xchar <- xinch(par("cin")[1])
		ychar <- yinch(par("cin")[2]) * 1.2
		xbox <- xinch(par("cin")[2] * 0.8)
		ybox <- yinch(par("cin")[2] * 0.8)
		yline <- 2 * xchar
		w <- 2 * xchar + max(strwidth(legend))
		h <- (length(legend) + 1) * ychar
		if (missing(y)) {
			if (is.list(x)) {
				y <- x$y
				x <- x$x
			}
		}
		if (!is.numeric(x) || !is.numeric(y)) 
			stop("non-numeric coordinates")
		if (length(x) <= 0 || length(x) != length(y)) 
			stop("differing coordinate lengths")
		if (length(x) != 1) {
			x <- mean(x)
			y <- mean(y)
			xjust <- 0.5
			yjust <- 0.5
		}
		if (!missing(fill)) {
			w <- w + xchar + xbox
		}
		if (!missing(pch)) {
			if (is.character(pch) && nchar(pch) > 1) {
				np <- nchar(pch)
				pch <- substr(rep(pch[1], np), 1:np, 
					1:np)
			}
			w <- w + 1.5 * xchar
		}
		if (!missing(lty)) 
			w <- w + 3 * xchar
		x <- x - xjust * w
		y <- y + (1 - yjust) * h
		xt <- rep(x, length(legend)) + xchar
		yt <- y - (1:length(legend)) * ychar
		if (bty != "n") {
			if (xlog) {
				x1 <- 10^x
				x2 <- 10^(x + w)
			}
			else {
				x1 <- x
				x2 <- x + w
			}
			if (ylog) {
				y1 <- 10^y
				y2 <- 10^(y - h)
			}
			else {
				y1 <- y
				y2 <- y - h
			}
			rect(x1, y1, x2, y2, col = bg)
		}
		x <- x + xchar
		if (!missing(fill)) {
			if (xlog) {
				x1 <- 10^xt
				x2 <- 10^(xt + xbox)
			}
			else {
				x1 <- xt
				x2 <- xt + xbox
			}
			if (ylog) {
				y1 <- 10^(yt - 0.5 * ybox)
				y2 <- 10^(yt + 0.5 * ybox)
			}
			else {
				y1 <- yt - 0.5 * ybox
				y2 <- yt + 0.5 * ybox
			}
			rect(xt, yt - 0.5 * ybox, xt + xbox, yt + 0.5 * 
				ybox, col = fill)
			xt <- xt + xbox + xchar
		}
		if (!missing(pch)) {
			if (xlog) 
				x1 <- 10^(xt + 0.25 * xchar)
			else x1 <- xt + 0.25 * xchar
			if (ylog) 
				y1 <- 10^yt
			else y1 <- yt
			points(x1, y1, pch, col = col)
			xt <- xt + 1.5 * xchar
		}
		if (!missing(lty)) {
			if (xlog) {
				x1 <- 10^xt
				x2 <- 10^(xt + 2 * xchar)
			}
			else {
				x1 <- xt
				x2 <- xt + 2 * xchar
			}
			if (ylog) 
				y1 <- 10^yt
			else y1 <- yt
			segments(x1, y1, x2, y1, lty = lty, col = col)
			xt <- xt + 3 * xchar
		}
		if (xlog) 
			x1 <- 10^xt
		else x1 <- xt
		if (ylog) 
			y1 <- 10^yt
		else y1 <- yt
		text(x1, y1, text = legend, adj = c(0, 0.35))
	}

----------------------------------------------------------------------
TASK:	legend (but see below)
STATUS:	Open
FROM:	<maechler@stat.math.ethz.ch>

	Arne, thank you for your very useful  bug findings and fixing.
	Your first two "patches" to  plot.c  are really ok.

	In your
	>> 3) The legend() function needs changes as well. I attach my
	>> quick hack below, but I think there are better solutions... :-)
	>> 
	>> legend <-
	>> function (x, y, legend, fill, col = "black", lty, pch, bty = "o", 
	>>         bg = par("bg"), xjust = 0, yjust = 1, ...) 
	>> .....
	there was one typo in the  ``if(!missing(fill))''  clause, you assigned
	x1,..y2, but then did not use them.

	Below I fixed this and found a way to make the whole  if(xlog) / (ylog)
	things a little more concise.
	This is a patch against "plain 0.49" ,  $RHOME/src/library/base/funs/ :

--- legend.~1~	Fri Jan 17 03:44:24 1997
+++ legend	Mon May 12 09:42:25 1997
@@ -2,13 +2,18 @@
 function(x, y, legend, fill, col="black", lty, pch, bty="o", bg=par("bg"),
 	xjust=0, yjust=1, ...)
 {
+	xlog <- par("xlog")
+	ylog <- par("ylog")
+	if (xlog) x <- log10(x)
+	if (ylog) y <- log10(y)
 	xchar <- xinch(par("cin")[1])
 	ychar <- yinch(par("cin")[2]) * 1.2
 	xbox <- xinch(par("cin")[2] * 0.8)
 	ybox <- yinch(par("cin")[2] * 0.8)
 	yline <- 2*xchar
 	w <- 2 * xchar + max(strwidth(legend))
-	h <- (length(legend)+1)*ychar
+	n.leg <- length(legend)
+	h <- (n.leg + 1) * ychar
 	if(missing(y)) {
 		if(is.list(x)) {
 			y <- x$y
@@ -39,23 +44,43 @@
 		w <- w + 3 * xchar
 	x <- x - xjust * w
 	y <- y + (1 - yjust) * h
-	xt <- rep(x, length(legend)) + xchar
-	yt <- y - (1:length(legend)) * ychar
-	if(bty != "n")
-		rect(x, y, x+w, y-h, col=bg)
+	xt <- rep(x, n.leg) + xchar
+	yt <- y - (1:n.leg) * ychar
+	if (bty != "n") {
+		xx <- c(x,x+w)
+		if (xlog) xx <- 10^xx
+		yy <- c(y,y-h)
+		if (ylog) yy <- 10^yy
+		rect(xx[1], yy[1], xx[2], yy[2], col = bg)
+	}
 	x <- x + xchar
 	if(!missing(fill)) {
-		rect(xt, yt - 0.5 * ybox,
-			xt + xbox, yt + 0.5 * ybox, col=fill)
+		xx <- c(xt,xt+xbox)
+		if (xlog) xx <- 10^xx
+		yy <- yt + c(-.5,.5) * ybox
+		if (ylog) yy <- 10^yy
+		rect(xx[1], yy[1], xx[2], yy[2], col = fill)
 		xt <- xt + xbox + xchar
 	}
 	if(!missing(pch)) {
-		points(xt + 0.25 * xchar, yt, pch, col=col)
+		x1 <- xt + 0.25 * xchar
+		if (xlog) x1 <- 10^x1
+		y1 <- yt
+		if (ylog) y1 <- 10^y1
+		points(x1, y1, pch, col = col)
 		xt <- xt + 1.5 * xchar
 	}
 	if(!missing(lty)) {
-		segments(xt, yt, xt + 2 * xchar, yt, lty=lty, col=col)
+		xx <- c(xt, xt + 2 * xchar)
+		if (xlog) xx <- 10^xx
+		y1 <- yt
+		if (ylog) y1 <- 10^y1
+		segments(xx[1], y1, xx[2], y1, lty = lty, col = col)
 		xt <- xt + 3 * xchar
 	}
-	text(xt, yt, text=legend, adj=c(0, 0.35))
+	x1 <- xt
+	y1 <- yt
+	if (xlog) x1 <- 10^x1
+	if (ylog) y1 <- 10^y1
+	text(x1, y1, text = legend, adj = c(0, 0.35))
 }
----------------------------------------------------------------------
TASK:	legend cont
STATUS:	Open
FROM:	<maechler@stat.math.ethz.ch>
	This time, I have at least tested it out under quite a few
	circumstances; the last patch (a few hours ago) would FAIL
	in many cases!

--- legend.~1~	Fri Jan 17 03:44:24 1997
+++ legend	Mon May 12 12:07:23 1997
@@ -2,18 +2,23 @@
 function(x, y, legend, fill, col="black", lty, pch, bty="o", bg=par("bg"),
 	xjust=0, yjust=1, ...)
 {
+  xlog <- par("xlog")
+  ylog <- par("ylog")
+  if (xlog) x <- log10(x)
+  if (ylog) y <- log10(y)
 	xchar <- xinch(par("cin")[1])
 	ychar <- yinch(par("cin")[2]) * 1.2
 	xbox <- xinch(par("cin")[2] * 0.8)
 	ybox <- yinch(par("cin")[2] * 0.8)
 	yline <- 2*xchar
 	w <- 2 * xchar + max(strwidth(legend))
-	h <- (length(legend)+1)*ychar
+  n.leg <- length(legend)
+  h <- (n.leg + 1) * ychar
 	if(missing(y)) {
 		if(is.list(x)) {
 			y <- x$y
 			x <- x$x
-		}
+    } else stop("missing y")
 	}
 	if(!is.numeric(x) || !is.numeric(y))
 		stop("non-numeric coordinates")
@@ -39,23 +44,36 @@
 		w <- w + 3 * xchar
 	x <- x - xjust * w
 	y <- y + (1 - yjust) * h
-	xt <- rep(x, length(legend)) + xchar
-	yt <- y - (1:length(legend)) * ychar
+  xt <- rep(x, n.leg) + xchar
+  yt <- y - (1:n.leg) * ychar
 	if(bty != "n")
 		rect(x, y, x+w, y-h, col=bg)
 	x <- x + xchar
 	if(!missing(fill)) {
-		rect(xt, yt - 0.5 * ybox,
-			xt + xbox, yt + 0.5 * ybox, col=fill)
+    xx <- cbind(xt, xt + xbox)
+    if (xlog) xx <- 10^xx
+    yy <- yt + cbind(rep(-0.5,n.leg), 0.5) * ybox
+    if (ylog) yy <- 10^yy
+    rect(xx[,1], yy[,1], xx[,2], yy[,2], col = fill)
 		xt <- xt + xbox + xchar
 	}
 	if(!missing(pch)) {
-		points(xt + 0.25 * xchar, yt, pch, col=col)
+    x1 <- xt + 0.25 * xchar
+    if (xlog) x1 <- 10^x1
+    y1 <- yt
+    if (ylog) y1 <- 10^y1
+    points(x1, y1, pch, col = col)
 		xt <- xt + 1.5 * xchar
 	}
 	if(!missing(lty)) {
-		segments(xt, yt, xt + 2 * xchar, yt, lty=lty, col=col)
+    xx <- cbind(xt, xt + 2 * xchar)
+    if (xlog) xx <- 10^xx
+    y1 <- yt
+    if (ylog) y1 <- 10^y1
+    segments(xx[,1], y1, xx[,2], y1, lty = lty, col = col)
 		xt <- xt + 3 * xchar
 	}
+  if (xlog) xt <- 10^xt
+  if (ylog) yt <- 10^yt
 	text(xt, yt, text=legend, adj=c(0, 0.35))
 }
----------------------------------------------------------------------
TASK:	lm.influence and weights
STATUS: Closed	
FROM:	<thomas@biostat.washington.edu>
	lm.influence() doesn't work correctly on weighted models
	(and thus on glm objects).
	[Added weights; lm.influence in R returns the differences in 
	coefs rather than the adjusted coefs which seems more sensible
	but incompatible ]
----------------------------------------------------------------------
TASK:	Adding List Elements by Name
STATUS:	Open
FROM:	<p.dalgaard@kubism.ku.dk>
	This works in Splus:
		> x<-list()
		> x[["f"]]<-1
		> zz<-"g"
		> x[[zz]]<-2 
	In R both variants fail unless the name is already on the
	list. The first one can be replaced by x$f, but there's
	seems to be no substitute for the other one (oh yes I found
	one, but it's not fit to print!). This comes up if you e.g.
	want to create a variable in a data frame with a name given
	by a character string.

----------------------------------------------------------------------
TASK:	Bug in "approx"
STATUS:	Open
FROM:
	When the function approx is called with the argument rule=2, one gets
	the error message
		Error: NAs in foreign function call (arg 6)
	Besides, the meaning of rule=1 or rule=2 is opposite to that described
	in the help text and used in S-plus.
	For example, in R:
		R> approx(1:10,2:11,xout=5:15,rule=1)
		$x
		 [1]  5  6  7  8  9 10 11 12 13 14 15
		$y
		 [1]  6  7  8  9 10 11 11 11 11 11 11
	R> approx(1:10,2:11,xout=5:15,rule=2)
	Error: NAs in foreign function call (arg 6)
	but in S-plus:
	> approx(1:10,2:11,xout=5:15,rule=1)
		$x:
		 [1]  5  6  7  8  9 10 11 12 13 14 15
		$y:
		 [1]  6  7  8  9 10 11 NA NA NA NA NA
		> approx(1:10,2:11,xout=5:15,rule=2)
		$x:
		 [1]  5  6  7  8  9 10 11 12 13 14 15
		$y:
		 [1]  6  7  8  9 10 11 11 11 11 11 11
	The reason for this bug can be found in the last lines of the code of
	approx:
		if (rule == 1) {
			low <- y[1]
			high <- y[length(x)]
		}
		else if (rule == 2) {
			low <- NA
			high <- low
		}
		else stop("invalid extrapolation rule in approx")
		y <- .C("approx", as.double(x), as.double(y), length(x), 
			xout = as.double(xout), length(xout), as.double(low), 
			as.double(high))$xout
		return(list(x = xout, y = y))
	If (rule == 2) the values of low and high are set to NA. Immediately
	afterwards, the foreign function "approx" is called with these values,
	leading to the error
		Error: NAs in foreign function call (arg 6)
	To obtain the same behavior as in S-plus (and as in the help-text) the
	commands for (rule == 1) and (rule == 2) have to be exchanged.

----------------------------------------------------------------------
TASK:	Incorrect warning message
STATUS:	Closed
FROM:	<thomas@biostat.washington.edu>
	R : Copyright 1997, Robert Gentleman and Ross Ihaka
	Version 0.49 Beta (April 23, 1997)
		R> f
		function () 
		{
			FALSE & matrix(FALSE, ncol = 1)
		}
		R> g
		function () 
		FALSE & matrix(FALSE, ncol = 1) 
		R> f()
		Warning in FALSE & matrix(FALSE, ncol = 1) : longer object length
		is not a multiple of shorter object length
		      [,1]
		[1,] FALSE
		R> g()
		      [,1]
		[1,] FALSE
	Is this weird or what?
	[ Was this a missed initiaization.  I suspect this is fixed ]
	[ I can't reproduce it now. ]

----------------------------------------------------------------------
TASK:	Seg violation in "return"
STATUS: Closed	
FROM:	<hornik@ci.tuwien.ac.at>
	R> x
	Error: Object "x" not found
	R> debug(t.test)
	R> t.test(rnorm(10))
	debug: choices <- c("two.sided", "greater", "less")
	Browse[1]> return()
	NULL
	R> x
	Error: Object "x" not found
	Browse[1]> return()
	Segmentation fault
	[ there was a seemingly aborted attempt to include contexts for
	  the browser to return from. Once this was fixed up the problem
	  was solved ]

----------------------------------------------------------------------
TASK:	Names and unlisting  (bug/feature)
STATUS:	Open
FROM:	hornik@ci.tuwien.ac.at
	R> l <- list("11" = 1:5)
	R> l
	$11
	[1] 1 2 3 4 5
	R> unlist(l)
	111 112 113 114 115 
	  1   2   3   4   5 
	I ran into this weekend ...

----------------------------------------------------------------------
TASK:	"all.names" function needed
STATUS:	Open
FROM:	<bates@stat.wisc.edu>
	I could not find the all.names function in R so I created the
	enclosed.  Comments, criticisms, or changes to a one-liner by creating
	nested anonymous functions are welcome.  I'll try to work out a
	corresponding all.vars function.

	### $Id: TASKS,v 1.30 1997/07/01 03:45:42 ihaka Exp $
	### Some replacement functions that are missing in R

	### Determine all the names (symbols) occuring in an object.
	### This is probably grossly inefficient.
	all.names <-
	  function (x) 
	{
	  if (mode(x) == "symbol") 
	    return(as.character(x))
	  if (length(x) == 0) 
	    return(NULL)
	  if (is.recursive(x)) 
	    return(unlist(lapply(as.list(x), all.names)))
	  character(0)
	}   
	### Local variables:
	### mode: R
	### End:

	And from Martin:
	Doug,

	your 'all.names' function
		[wow, I didn't even know it in S..]
	seems to have been written with S in your mind;
	you are exactly demonstrating some of the 'fine' differences between  R & S

	>1> all.names <- function (x) 
	>2> {
	>3>   if (mode(x) == "symbol")  return(as.character(x))
	>4>   if (length(x) == 0)       return(NULL)
	>5>   if (is.recursive(x))      return(unlist(lapply(as.list(x), all.names)))
	>6>   character(0)
	>7> }   

	1) length(x) is not always defined in R; e.g. it is NOT for functions.
	   --> Delete line 4  

	2) functions  are NOT lists and cannot be coerced to,
	   which makes line 5 fail for function objects.

	As a matter of fact, I once was also a bit interested in this.
	At that time, 'args' did not yet exist, and I wanted to abuse 'as.list' for
	functions.
	I was told that this is 'bad' (functions have nothing to do with
	lists; in R, functions can have a defining environment going with
	them...) and 'args' is now provided which helps my most immediate
	need.

	In short: I don't think  you can define an  all.names(.)
	function which works with functions arguments, in the
	current version of R.


----------------------------------------------------------------------
TASK:	"sys.function" problem
STATUS:	Open
FROM:	<bates@stat.wisc.edu> + <maechler@stat.math.ethz.ch>
	This was either an attempt to get an early lead in some
	future obfuscating R contest or a way of getting around
	the different scoping rules of R and S.

	I attempted to create a recursive anonymous function to be
	called within another function.  You may want to stop
	reading for a bit and consider how that would be done.
	That is, how do you recursively call a function that has
	never been assigned a name?

	OK, you're back.  You probably came up with a better solution
	than I did but I used (sys.function())(arg) to do the
	recursion.  The piece of code looks like
	  flist <- (function(x) {
	    if (mode(x) == "call") {
	      if (x[[1]] == as.name("/")) 
		return(c(sys.function()(x[[2]]), sys.function()(x[[3]])))
	      if (x[[1]] == as.name("(")) 	# for R
		return(sys.function()(x[[2]]))
	    }
	    if (mode(x) == "(") return(sys.function()(x[[2]])) # for S
	    list(x)
	  })(getGroupsFormula(data, form, ...)[[2]])
	  ## I know it's horribly obscure.
	  ## Blame Bill Venables for teaching me this.

	Regretably, it doesn't work in R.  Using the debugger one
	finds that sys.function() returns the function being called
	the first time through but the second time through it
	returns NULL.  Is this a bug or a feature?

----------------------------------------------------------------------
TASK:	Matrix multiply problems
STATUS:	Open
FROM:	<thomas@biostat.washington.edu>
	Both of these used to work and seem useful and harmless:
	R> matrix(1,ncol=1)%*%c(1,2)
	Error in matrix(1, ncol = 1) %*% c(1, 2) : non-conformable arguments
	R> matrix(1,ncol=1)*(1:2)
	Error: dim<- length of dims do not match the length of object

----------------------------------------------------------------------
TASK:	Updating in lm / glm
STATUS:	Closed?
FROM:	<thomas@biostat.washington.edu>
	Three bugs and 2.5 fixes.

	1. To make update() work with a new formula for glms, change the first
	line of the glm() function from
	call <- sys.call(
	to
	call<-match.call()
	(this means that the formula component of the returned call is labelled so
	that update can find it)

	2. update.lm doesn't do anything with its weights= argument. Add
		if (!missing(weights))
			call$weights<-substitute(weights)
	Similarly, to get update to work properly on glms you need a lot more of
	these if statements (see update.glm at the end of the message).

	3. update.lm evaluates its arguments in the wrong frame. It creates a
	modified version of the original call and evaluates it in 
	sys.frame(sys.parent()).  If update.lm is called directly this is correct,
	but if it is called via update() the correct frame is
	sys.frame(sys.parent(2)). Worse still, if it is called by NextMethod()
	from another update.foo() the correct frame is still higher up the list.

	My solution (a bit ugly) is to move up the list of enclosing calls
	checking at each stage to see if the call is NextMethod, update or an
	update method.  It can be seen at the end of update.glm at the bottom of
	this message, and something of this sort needs to be added to other update
	methods.
	[ I've added a new type of context- CTXT_GENERIC, all generic functions
	 have their context set to this just before the method is applied and
	 revert to CTXT_RETURN after the method has been applied. This seems
	 to provide the required result. The other fixes were added in. RG]

----------------------------------------------------------------------
TASK:	"write" function
STATUS:	Open?
FROM:	<Kurt.Hornik@ci.tuwien.ac.at>
	Following my posting of a write.table() function, Martin
	suggested that one could have a generic write() function
	and special methods for e.g. time series, data frames, etc.

	Well, a month has passed since ...

	What does everyone think?  Is it a good idea, or would
	write.table() be enough?  If we think that it is not enough,
	which arguments should the write methods typically allow?
	What about

	write.xxx (x,		# object
		   file =       # filename, default stdout
                   append =     # obvious
                   sep =	# obvious
		   eol =        # end of line char
                   ...)

	???

	On the other hand, it seems clear that something like
	write.table() is nice, and what it should do.  But what
	about classes other than data.frame?

	Martin Maechler:

	Note that S has a  write(.)  function  which would be our
	write.default(.)

	your	write.table	    would be our 
		write.data.frame

	The only addition would be a  'write.matrix' which would be 'like'
	write.data.frame, the only problem being that  'matrix' is not a
	class (yet).  [Note that in S4, everything has a class; 
		   I'm voting for matrices to have a class in R  ..]
	write.default  could 'despatch' to write.matrix if  x  is a matrix.

----------------------------------------------------------------------
TASK:	"ls.print" problem
STATUS:	Open
FROM:	<VENKAT@biosta.mskcc.org>
	ls.print produces error that I don't seem to be able to
	trace.  Output of the commands as follows: (hyeung is a
	24x2 matrix of data)
	-------------------------------------------------
	> summary(hyeung)
	       x.1             x.2
	 Min.   : 28.0   Min.   : 10.0
	 1st Qu.: 72.0   1st Qu.: 87.5
	 Median : 86.5   Median : 92.5
	 Mean   : 81.0   Mean   : 82.5
	 3rd Qu.: 97.0   3rd Qu.:100.0
	 Max.   :100.0   Max.   :100.0
	> summary(lsfit(hyeung[,1],hyeung[,2]))
		  Length Class  Mode
	coef       2     -none- numeric
	residuals 24     -none- numeric
	intercept  1     -none- logical
	qr         6     -none- list
	> ls.print(lsfit(hyeung[,1],hyeung[,2]))
	trace: ls.print(lsfit(hyeung[, 1], hyeung[, 2]))
	Error: missing value in ``n1 : n2''

----------------------------------------------------------------------
TASK:	Comparisons with zero length things
STATUS:	Open
FROM:	<thomas@biostat.washington.edu>
	<maechler@stat.math.ethz.ch>

		Thomas:
	Any comparison with NULL generates an error
	Error: comparison is possible only for vector types
	whereas in S(-PLUS) it gives NA, which seems more sensible.
	Along similar lines, comparison with a length 0 vector returns
	logical(0) in R but NA in S. 

		Martin:
	Isn't  logical(0)  more  logical than  NA ?
	I agree that it would be best  (convenience)
	if 'NULL==1' returned the same as 'numeric(0)==1'.
	At the moment, I don't see why compatibility with S  should be
	important here:
			if( NULL == anything)  
	or, e.g.,	if( numeric(0) == numeric(0) )

	give an error anyway, i.e., you have to test for length 0
	_anyway_ in the cases where one comparison argument may
	have zero length.

		Thomas:
	I didn't (previously) make any comment on this -- I only
	said that NA was more logical than an error message.
	However, the advantage of returning NA is that NA | TRUE
	is TRUE, NA & FALSE is FALSE, which doesn't happen with
	logical(0). Also, from a compatibility point of view one
	of them is tested with is.na(), the other with length(),
	so it can matter which one you use.  Of course no-one should
	deliberately write code where it matters, but these things
	happen.
	It seems in fact that logical(0) | TRUE causes R to freeze
	(R0.49, sparc solaris).

		Robert:
	Well, we thought
	  logical(0) & T should return logical(0)
	  logical(0) | T should return logical(0)
	  already we have NA | T returns T
		     and  NA & T returns NA

		Martin:
	Ok, given the above argument, returning NA is logical, too.
	However, I'd also argue that  
		logical(0) | TRUE	-> TRUE
		logical(0) & FALSE      -> FALSE

		logical(0) & TRUE	-> logical(0)
		logical(0) | FALSE      -> logical(0)

	    ThLu> It seems in fact that logical(0) | TRUE causes R to freeze
	    ThLu> (R0.49, sparc solaris).
	Yes:
	> logical(0) | TRUE
	Warning in logical(0) | TRUE : longer object length
		is not a multiple of shorter object length
	Floating exception
	~~~~~~~~~~~~~~~~~~ [and 'core' dump]

----------------------------------------------------------------------
TASK:	Complex Nits
STATUS:	Closed
FROM:	<la-jassine@aix.pacwan.net>
	Mod, Re, Im, and Conj should work for Real numbers using as.complex
	complex should be
	   complex <- function (n = 0, real = numeric(), imaginary = numeric())
	not 
	   complex <- function (n = 0, real = numeric(), imag = numeric()) 

----------------------------------------------------------------------
TASK:	Misc
STATUS:	Open
FROM:	<la-jassine@aix.pacwan.net>
	Here are two small problems I've pointed out before, but
	still seem to be in 0.49.

	1/ getenv() should return everything, not complain missing item.

	2/ In summary.default
	 ...
			sumry[i, 2] <- if (is.object(ii)) 
				 class(ii)
	should be changed to
	...
			sumry[i, 2] <- if (is.object(ii)) 
				paste(class(ii), collapse=" ")

	so that it works with lists of lists.
	(This fix was suppose to be added to Splus 4.)

----------------------------------------------------------------------
TASK:	Method lookup for "print"
STATUS:	Open
FROM:	<la-jassine@aix.pacwan.net>
	I have  always thought that typing the name of an object
	generated a call to the print method for the object, however,
	(in 0.49) I redefined the generic print method as

	print <- function(x, ...)
	 {if (is.tframe(x))  UseMethod("print.tframe")
	  else UseMethod("print")
	 }

	Now I have an object z which returns TRUE to is.tframe(z) and
	> class(z)
	[1] "ts"     "tframe"
	Then
	> print(z)
	[1] 1981.50 2006.25    4.00
	But
	> z
	Error: comparison is possible only for vector types
	> traceback()
	[1] "c(\"print.ts(structure(c(1981.5, 2006.25, 4), class = c(\\\"ts\\\",
	\\\"tframe\\\"\", "
	[2] "c(\"print(structure(c(1981.5, 2006.25, 4), class = c(\\\"ts\\\",
	\\\"tframe\\\"\", "   

	This is generating a call to the class method print.ts
	rather than to print.tframe.ts as is done when I use
	print(z).  If my understanding that typing the name of an
	object should generate a call to the print method for the
	object then this is a bug. Otherwise, could someone please
	explain to me what it does. Thanks.

----------------------------------------------------------------------
TASK:
STATUS:
FROM:
	Here are four problems with ts:

	1/  ts matrix subscripting should support drop=F:
	> z<- matrix(1:10,5,2)
	> z <-ts(z)
	> z[,1,drop=F]
	Error in [.ts(z, , 1, drop = F) : unused argument to function


	2/  == and other comparisons with non-ts matrices should work:
	> z <- matrix( 1:10,5,2)
	> ts(z)
	Time-Series:
	Start = c(1, 1) 
	End = c(5, 1) 
	Frequency = 1 
	     [,1] [,2]
	[1,]    1    6
	[2,]    2    7
	[3,]    3    8
	[4,]    4    9
	[5,]    5   10
	> z == ts(z)
	Error: invalid time series parameters specified
	> 

	3/ The generic functions start and end need default methods
	to return a result for matrices as previously and in S.
	The following seems to work.

		start.default <- function (x) start(ts(x))
		end.default   <- function (x)   end(ts(x))


	4/ In the function start.ts (and in end.ts) ts[1] in the
	last line is not defined. Perhaps I am missing something?

	start.ts
	function (x) 
	{
		ts.eps <- .Options$ts.eps
		if (is.null(ts.eps)) 
			ts.eps <- 1e-06
		tsp <- attr(as.ts(x), "tsp")
		is <- tsp[1] * tsp[3]
		if (abs(is - round(is)) < ts.eps) {
			is <- floor(tsp[1])
			fs <- floor(tsp[3] * (tsp[1] - is) + 0.001)
			c(is, fs + 1)
		}
		else ts[1]
	}
 
----------------------------------------------------------------------
TASK:	False warnings
STATUS:	Open
FROM:	<la-jassine@aix.pacwan.net>
	In R 0.49 comparison of logic matrices with & and | seems
	to sometimes generate false warning messages about longer
	object length is not a multiple of shorter object length.
	I have not been able to isolate the exact circumstances.

----------------------------------------------------------------------
TASK:	"eigen" shortfall
STATUS:	Closed
FROM:	<p.dalgaard@kubism.ku.dk>
	eigen() seems to work for symmetric matrices only. This is
	out of sync with the help file.
	[ Source code adjusted to fit the documentation. ]

----------------------------------------------------------------------
TASK:	abline + coefficients
STATUS:	Closed
FROM:	<nobu@psrc.isac.co.jp>
	I found a little different behavior of R with S.
	at R-0.49:
	    > a
	    [1] 12 23 22 34 44 54 55 70 78
	    > plot(a)
	    > abline(lsfit(seq(1,len=length(a)), a))
	    Error: no applicable method for "coefficients"
	at S (from AT&T '92) result draw coefficient line without error.
	Then I think to need define a function as followed:
	    coefficients.default <- function(x) x$coef
	[ Default method already added for Doug Bates. ]

----------------------------------------------------------------------
TASK:	beta and lbeta error
STATUS:	Closed
FROM:	<maechler@stat.math.ethz.ch>
	The beta(.)  and  ln(beta(..))  functions are not giving
	proper results in R-0.49.  This does NOT affect usual
	beta-distribution calculations, since the internal  beta(.)
	and lbeta(.) are okay.
	beta(1,2)
	[1] -0.6931472
	exp(beta(1,2))
	[1] 0.5
	lbeta(3,4)
	[1] 3
	[ Caused by a cut/paste typo in names.c ]

----------------------------------------------------------------------
TASK:	"pbeta"/"qbeta"
STATUS:	Open?
FROM:	<maechler@stat.math.ethz.ch>
	(When using the new  pbeta(.); this actually DOES seem to matter).
	For qbeta(.), 
	I now have an  R- function with quite a bit of diagnostic output,
	so I can easily see what's going,  AND the function has  
		lower, upper = 1-lower
	as extra arguments.
	I found in a few tests, that "all" problems seem to be gone, when I
	brutally set  lower = 0 (and therefore  upper = 1).
	Unfortunately, this is not directly reproducible with the C-version.
	In any case, this seems to make it unnecessary to use 
	the  good special formulae for   qt(x, df)  for high 'df'.
	Let you know more when I see through!

----------------------------------------------------------------------
TASK:	dhyper.c
STATUS:	Closed
FROM:	<maechler@stat.math.ethz.ch>
	Line 30 should be changed from
	if (NR <= 0 || NR <= 0 || n <= 0 || n > N)
	to                      ^-- typo: "R" should be "B"
	if (NR < 0 || NB < 0 || n < 0 || n > N)
	(NR==0 or NB == 0  should not be a DOMAIN_ERROR)

----------------------------------------------------------------------
TASK:	ISO-latin1 characters 
STATUS:	Open
FROM:	<maechler@stat.math.ethz.ch>
	There seems to be a problem in print.default with some
	ISO-latin1 characters (the chars AFTER ASCII in western
	Europe...) if they appear in strings.  (no problem if they
	are part of a function comment, see below).

	Some of the characters lead to 4 character Hex-codes being
	printed instead:  "" ## ^u    prints as "0xFB"

	If you use the funny characters in comments of functions,
	they are stored and printed properly.

	HOWEVER: In a few rare cases, the strings are not even
	PARSED properly; the line 'ISOdiv <- ..' below gives a
	SYNTAX error.

	The following code shows the symptoms :
	 -- ONLY if  the e-mail between here and your place is
	 8-bit clean! -- (else: get it
	ftp://ftp.stat.math.ethz.ch/U/maechler/R/string-test.R )

	frenchquotes <- "..."  ## <<...>>
	frenchquotes

	Umlaute <- " " # = "a "o "u  "A "O "U
	Umlaute #- only the last one is not printed properly...

	A.accents <- " " # `a 'a ^a "a oa ae  `A 'A ^A "A oA AE
	A.accents
	EI.accents <- " "
	EI.accents
	O.accents <- ""
	O.accents

	U.accents <- ""
	U.accents

	ISO24x <-  " " #octal 241..257
	ISO26x <- " " #octal 260..277

	##--- THIS IS a Problem: It gives a SYNTAX error !
	ISOdiv <- "    " 
	##-- One of these characters even was producing the same as  'q()' !!

	aa_ function(x) {
	  x^2
	  ##- frenchquotes <- "..."  ## <<...>>
	  ##- Umlaute <- " " # = "a "o "u  "A "O "U
	  ##- A.accents <- " " # `a 'a ^a "a oa ae  `A 'A ^A "A oA AE
	  ##- EI.accents <- " "
	  ##- O.accents <- ""
	  ##- U.accents <- ""
	  ##-
	  ##- ISO24x <-  " " #octal 241..257
	  ##- ISO26x <- " " #octal 260..277
	  ##- ISOdiv <- " " ##-- OMITTED further: SYNTAX error !!
	}
	aa

----------------------------------------------------------------------
TASK:	String length problems
STATUS:	Closed
FROM:	<maechler@stat.math.ethz.ch>
	This is not a  cat(.) but a  string storing/parsing problem:
	nchar("\n\n")  # gives  2  instead of 3
	[ Hmmm.  Was this typed to readline I wonder?  There it  ]
	[ seems that ^L must be escaped with ^V.  Using the ANSI ]
	[ \f will now produce a literal formfeed.  Indeed, using ]
	[ any of the ANSI C escapes will work.			 ]

----------------------------------------------------------------------
TASK:	Batch Mode Errors
STATUS:	Closed?
FROM:	<thomas@biostat.washington.edu> + MM
	Errors which occur during batch mode execution produce
	a cascade of error messages.  We now print the first error
	message and abort.  I don't think it makes much sense to
	continue execution after an error.  I suppose we could
	parse the remainder of the input and not execute.  Glim77
	used to do this.

----------------------------------------------------------------------
TASK:	lsfit problem (really cbind memory error)
STATUS:	Closed
FROM:	<ncv@ap.cc.affrc.go.jp>
	I would like to report my problem in running R with a large data set.
	Something has been change in the lsfit() function, especially the
	parameters "wt" and "yname".
	Your help is highly appreciated.
	[ This was an old bug the reason I mention it is because    ]
	[ in looking at the example code he sent in I noticed that  ]
	[ it was taking 30Mb to read a 176 x 166 data frame.  A     ]
	[ little calulation shows that 0.5Mb should have been       ]
	[ enough!  It seems that Robert and I were working at cross ]
	[ puposes in scan and read.table.  We ended up allocating   ]
	[ n x n x p rather than n x p ... ].

----------------------------------------------------------------------
TASK:	Documentation Nit
STATUS:	Closed
FROM:	<Kurt.Hornik@ci.tuwien.ac.at>
	The documentation for ls/objects has
		ls(name, pos=2, envir=sys.frame(sys.parent()),
		   all.names=FALSE, pattern)
	but the code has
		ls <-
		function (name, pos = -1, envir = NULL,
			  all.files = FALSE, pattern)
	[ At one time these were equivalent.  Are they still? ]

----------------------------------------------------------------------
TASK:	Fontend
STATUS:	Open
FROM:	
	Some time ago there was the suggestion to add a PLATFORM
	subdir level for bin (and eventually the library subdirs
	with `binaries'), and the idea to have the shell wrapper
	automagically call the right binary.

	I mentioned that one might be able to use the shell variables
	OSTYPE and HOSTTYPE for that, noticing however that e.g on
	my Debian Linux/GNU/ix86

			bash	tcsh
	OSTYPE		Linux	linux
	HOSTTYPE	i386	i386-linux

	Hmm ... It seems (a colleague just checked that) that these
	variables are not POSIX either, and hence I'd say rather
	useless for our purpose.

	In the absence of a reliable run-time possibility to
	determine the current platform, it seems to be natural to
	use `platform' as obtained at compile-time for possibly
	distinguishing the various binaries etc, and leave it at
	the discretion of the sysadmin to ensure that the R script
	in the path calls the right binary.

	If I am missing something obvious, please let me know.


----------------------------------------------------------------------
TASK:	Martin's Least Favourite ... Part 1.
STATUS:	Closed
FROM:	<maechler@stat.math.ethz.ch>
	1) print(2^30, digits = 12) #-  exponential form; unnecessarily!
	 formatC(2^30, digits = 12) #- shows you what you'd want above
	 ## S-plus is okay here; note that the problem also affects
	 ##	paste(.)  & format(.) :
	 options(digits=10)
	 paste(2^(4*1:8))
	 S-plus gives
	[1] "16"         "256"        "4096"       "65536"      "1048576"   
	[6] "16777216"   "268435456"  "4294967296"
	 whereas R gives
	[1] "16"              "256"             "4096"            "65536"          
	[5] "1048576"         "1.6777216e+07"   "2.68435456e+08"  "4.294967296e+09"
	[ This was due to overzealous testing in formatReal.  I have   ]
	[ replaced a hard-coded "8" with the specified "digits" value. ]


----------------------------------------------------------------------
TASK:	Martin's Least Favourite ... Part 2.
STATUS:	Closed
FROM:	<maechler@stat.math.ethz.ch>
	2) This one has been reported (in slightly different form)
	   >> Date: Mon, 10 Mar 1997 09:46:37 +0100 (MET)
	   >> From: Martyn Plummer <plummer@iarc.fr>
	   >> To: r-testers@stat.math.ethz.ch

	   >> #4) If you put a few lines of comments at the start of a function,
	   >>     then the comments always appear *after* the first line of code. 

	This is REALLY painful; try, e.g.,

	fcat <- function(..., f.dig= 4, f.wid = f.dig +5, f.flag = ' ', nl = TRUE,
			 file = "", sep = " ",
			 fill = FALSE, labels = NULL, append = FALSE)
	{
	  ## Purpose: Formatted CAT -- for printing 'tables'
	  ## ----------------------------------------------------------------------
	  ## Author: Martin Maechler, Date: 12 May 97
	  l <- unlist(lapply(list(...), formatC,
			     wid= f.wid, digits= f.dig, flag= f.flag))
	  cat(l, if(nl)"\n", file=file, sep=sep, fill=fill,labels=labels, append=append)
	}

	# and look how it prints:
	fcat

	Even worse, some comments are silently lost (yes, I know in some
	sitatuations,  S also loses comments) : 

	ex <- 
	##
	## S version 4 likes comments like these.  
	## ----------- They automagically become  on-line help.
	## R just swallows them up into /dev/null...
	##
	function(a,b)
	{
		a + b
	}
	[ I have fixed this a bit.  It should be possible to ]
	[ add the Sv4 behavior                               ]

----------------------------------------------------------------------
TASK:	rep(.) and aperm(.) lose names(.) and dimnames(.)
STATUS:	Closed
FROM:	<maechler@stat.math.ethz.ch>
	The following patches fix the problem.
	For aperm, it's quite important to keep dimnames(.);
	for rep(.), it's arguable, however S(-plus) does it...

	However, it would probably be better to this in the '.Internal'
	code for all attributes.

	Patch to be applied in		$RHOME/src/library/base/funs/ 

--- rep~	Sun Nov 24 23:42:29 1996
+++ rep		Tue May 20 18:20:12 1997
@@ -5,6 +5,7 @@
 	if (missing(times))
 		times <- ceiling(length.out/length(x))
 	r<-.Internal(rep(x,times))
+	if(!is.null(nm <- names(x))) names(r) <- .Internal(rep(nm, times))
 	if (!missing(length.out))
 		return(r[1:length.out])
 	return(r)

--- aperm~	Sun Nov 24 23:42:20 1996
+++ aperm	Tue May 20 18:20:10 1997
@@ -7,5 +7,7 @@
 		if(!all(sort(perm)==1:length(perm)))
 			stop("perm is not a permutation")
 	}
-	.Internal(aperm(a,perm,resize))
+	r <- .Internal(aperm(a, perm, resize))
+	if(!is.null(dn <- dimnames(a))) dimnames(r) <- dn[perm]
+	r
 }
	[ Patch applied, but it might be nice to have this adjustment ]
	[ in the internal code. ]

----------------------------------------------------------------------
TASK:	Plot.default
STATUS:	Closed
FROM:	<maechler@stat.math.ethz.ch>
	A simple example:
		plot(1:10, 1:10, main = "TITLE", lab = c(10,10,7))
		 #> Error: invalid subscript type
	The reason is the call to  axis(1, ...) in  plot.default(.).
	plot.default has the  ...  arguments in order to pass the many
	different possible 'par' options to it's own subfunctions.
	Currently, plot.default has
	 plot.xy(xy, type, col = col, pch = pch, cex = cex, bg = bg,
		lty = lty, ...)
	 axis(1, ...)
	 axis(2, ...)
	 box(...)
	title(main = main, xlab = xlab, ylab = ylab, ...)
	In order for this to work, all the subfunctions MUST be
	tolerant to all possible argument specifications.
	axis(.) is NOT  which leads to the above  Error.
	A different approach would be to "analyze"  list(...),
	extract relevant parameters and pass them to the different
	sub-functions of
		plot.default(.).
	[ The problem here is that "axis" has an argument called ]
	[ "labels" which is matching the "lab=" spec.  Since the ]
	[ ... is just passed on, the usual matching strategy of  ]
	[ prefering exact matches fails.  There is an easy fix   ]
	[ however.  Pass the values down using a pars=list(...)  ]
	[ (I know it's a horrible undocumented kludge, but ...   ]

----------------------------------------------------------------------
TASK:	Resetting Graphical Parameters
STATUS:	Open
FROM:	<maechler@stat.math.ethz.ch>
	BY THE WAY:
	  It would be nice to be able to say
		par(reset = TRUE)  
	  (or similar) for resetting all the graphical parameters to their
	(device-dependent) default values.
	[ This will require a little work.  Perhaps the easiest thing   ]
	[ to do is to add a new device driver call "reset".  This would ]
	[ be best left to the multiple acyive device driver project.    ]

----------------------------------------------------------------------
TASK:	Overall Titles
STATUS:	Closed
FROM:	<maechler@stat.math.ethz.ch>
	In S, I can have an "overall" title in a multi-figure plot :
		par(mfrow=c(2,2), oma = c(0,0,2,0))
		frame() #- !
		mtext("Sine Functions", cex=2, outer =T)
		x_1:100
		for(i in 1:4) plot(x, sin(i*pi*x/100), main=paste(i),
			type = 'l', col = 1+i)
	In R, this doesn't work as it should,  with and without
	the 'frame()' statement.
	((where is the bug?  It's not quite clear to me))
	Is there a way at all to write an "overall" title in this situation ?

	[  The problem was that "mtext" was marking the first plot  ]
	[  dirty even though nothing was being drawn in it.  Now    ]
	[  if outer=TRUE, the plot is not marked dirty.             ]

----------------------------------------------------------------------
TASK:	No Warning in ":"
STATUS:	Closed
FROM:	<Friedrich.Leisch@ci.tuwien.ac.at>
	In R it is possible to write nonsense 
	R> 0.5:4:3:9:8:5
	[1] 0.5 1.5 2.5 3.5 4.5
	and never be warned about it, Splus does the expected thing:
	Splus> 0.5:4:3:9:8:5
	[1] 0.5 1.5 2.5 3.5 4.5
	Warning messages:
	1: Numerical expression has 4 elements: only the first used in: 0.5:4:3
	2: Numerical expression has 3 elements: only the first used in: 0.5:4:3:9
	3: Numerical expression has 9 elements: only the first used in: 0.5:4:3:9:8
	4: Numerical expression has 8 elements: only the first used in: 0.5:4:3:9:8:5
	[  But what about a more general ":" which does allow vector ]
	[  arguments.						     ]

----------------------------------------------------------------------
TASK:	.Options not working in all cases
STATUS:	Open
FROM:	<maechler@stat.math.ethz.ch>
	The .Options vector had been introduced a while ago after my
	suggestion (see Ross's E-mail below).  .Options$digits is used
	be default in several  print methods (eg print.lm), however,
	deparse(.) e.g., uses options()$width, and not .Options$width.

	Another problem is that  .Options
	is still not in the documentation (on-line help).
	Before one could add it there, we'd need ``the specs''.

	I think the (at least my) idea was that
		options(.)  queries or sets elements in the   .Options  list
	and all functions -- including the internal ones -- use  .Options.
	As far as I know, this is what S does.
	Currently, this is NOT the case in R.

	Ross said a while ago:

   >>> From: Ross Ihaka <ihaka@stat.auckland.ac.nz>
   >>> Date: Wed, 11 Dec 1996 17:10:59 +1300 (NZDT)
   >>> To: Martin Maechler <maechler@stat.math.ethz.ch>
   >>> Cc: R-testers mailing list <R-testers@stat.math.ethz.ch>
   >>> Subject: R-alpha: options() and .Options -- ?

    Ross> Martin Maechler writes:
    >> This is not a bug report, rather than some remarks as a
    >> "request for comments":
    >>
    >> It is clear that  options( foo = bar )
    >> sets the option and also updates the builtin()  .Options  list :
    >> 
    >> > options(myopt = pi)
    >> > .Options$my
    >> [1] 3.14159265
    >> 
    >> In S-plus, it was (is) possible to use .Options locally in a function
    >> frame in order to just affect some options during evaluation of that
    >> function.

    Ross> I have made some changes so that such local assignments to .Options
    Ross> will work.  The down side is that such assignments will also work at
    Ross> top level with the changes shadowing the real system options.

    Ross> This also may be ok.  It would have the advantage that options would
    Ross> then be preserved from session to session.  Is this a good idea or a
    Ross> bad idea?

----------------------------------------------------------------------
TASK:	Complex inaccuracy
STATUS:	Closed
FROM:	<maechler@stat.math.ethz.ch>
	> Re(1i)
	[1] 2.497599e-307
	rather than 0 whereas Im(as.complex(1)) gives 0 as it should.
	[ This was an uninitialized variable problem in mkComplex, ]
	[ which is called by yyparse to create complex numbers.    ]

----------------------------------------------------------------------
TASK:	"grep" and backreferences
STATUS:	Closed
FROM:	<p.dalgaard@kubism.ku.dk>
	In answer to <thomas@biostat.washington.edu>:
	I strongly suspect that no number of \s will make it work
	as long as do_grep() in main/character.c contains this
	line:
		eflags = REG_NOSUB;
	[  We now use EFLAGS = 0; instead.  ]

----------------------------------------------------------------------
TASK:	New Apropos Function
STATUS:	Closed
FROM:	<Kurt.Hornik@ci.tuwien.ac.at>
	Martin and I have `written' a function apropos() for finding
	all objects with names matching pattern.  I attach code
	and documentation.  Perhaps one could include it in the
	distribution proper.
	[ Added to base library for Version 0.50. ]

----------------------------------------------------------------------
TASK:	Random query ...
STATUS:	Closed
FROM:	<Kurt.Hornik@ci.tuwien.ac.at>
	Still trying to port Brian's class TB ...
	I need to find replacements for seed_in()/seed_out() and
	unif_rand().  Looks like the first works with
	GetSeeds()/PutSeeds().  Can anyone help me with the second
	one?
	[ Implemented these so they work as described in the S-Plus ]
	[ programmers manual.  Also added S_realloc at Kurt's       ]
	[ request. ]

----------------------------------------------------------------------
TASK:	var / cov
STATUS:	Closed
FROM:	<thomas@biostat.washington.edu>
	var() handles missing values in a very strange way. It is
	not what the documentation says
		> var(c(NA,1:10))
		[1] 0
		> var(1:10)
		[1] 9.166667
		This is because sum() handles NA incorrectly
		> sum(NA)
		[1] 0
		> sum(NA,na.rm=T)
		[1] 0
		> sum(NA,na.rm=F)
		[1] 0
	Also the documentation gives a pairwise= option to var()
	which isn't in the function.
	[ We need a general resolution to this ... ]

----------------------------------------------------------------------
TASK:	"factor" problem
STATUS:	Closed
FROM:	<hornik@ci.tuwien.ac.at>
	* The documentation for factor() says,
		If exclude is set to a zero length vector, then
		any NA values in x are used for form a new level
		for the factor.  This means that there will be no
		NA values in the result.
	Perhaps I don't really understand this, but
	R> x <- factor(c(1:3, NA), exclude=numeric(0))
	R> x
	[1]  1  2  3 NA
	R> levels(x)
	[1] "1" "2" "3"
	[  Fixed.  The main problem was that deep inside match  ]
	[  we has a test which could be  NaN == NaN which is    ]
	[  always false.                                        ]

----------------------------------------------------------------------
TASK:	inaccurate error messages in coerce.c
STATUS:	Closed
FROM:	<hornik@ci.tuwien.ac.at>
	* coerce.c has two error messages of the form
        error("use \"factor\", \"ordered\", \"cut\" or \"code\" to create factors\n");
	but there is no function `code'.

----------------------------------------------------------------------
TASK:	"cat" problem
STATUS:	Closed
FROM:	<hornik@ci.tuwien.ac.at>
	* cat() is a bit inconsistent:
	R> cat(x, sep = "&")
	1&2&3&4R> cat(x, sep = "&\n")
	1&
	2&
	3&
	4
	R>
	Actually, a final newline is added whenever sep contains
	a newline.
	>From src/main/builtin.c:

        nlsep = 0;
        for (i = 0; i < LENGTH(sepr); i++)
                if (strstr(CHAR(STRING(sepr)[i]), "\n")) nlsep = 1;

        ...

        if ((pwidth != INT_MAX) || nlsep)
                Rprintf("\n");

	I am not sure this is the right thing to do.
	(In particular, it makes it rather messy to incrementally
	build data files with `explicit' end-of-line strings (such
	as "\\") by appending via cat().)
	[ This is the way S does it! ]

----------------------------------------------------------------------
TASK:	Return type of ":"
STATUS:	Closed
FROM:	<maechler@stat.math.ethz.ch>
	which reminds me of bug report  I had sent a while ago,
	I think in pre-alpha times:
	In R,  1:n is   double (aka 'real') and not integer.

----------------------------------------------------------------------
TASK:	Dyn.load utilties
STATUS:	Closed
FROM:	<maechler@stat.math.ethz.ch>
	In S(plus), I can write functions using code fragments like
		if(!is.loaded(symbol.C("my_C_fun")))
			dyn.load("......../my_C_fun.o")
		r <- .C("my_C_fun",
			x = x,
			n = n, 
			...
			)
	which I would like to have in R, too.
	The S-plus help page on this subject says :
S+>> Code Availability
S+>> 
S+>> DESCRIPTION:
S+>>        is.loaded returns a logical value  stating  if  the  given
S+>>        object   is  currently  loaded  into  S-PLUS.  dump.loaded
S+>>        returns a list of loaded symbols.  The "symbol"  functions
S+>>        return the symbol that would be associated with a name.
S+>> 
S+>> USAGE:
S+>>        is.loaded(symbol)
S+>>        dump.loaded()
S+>>        symbol.C(name)
S+>>        symbol.For(name)
S+>>        symbol.S(name)
S+>> 
S+>> REQUIRED ARGUMENTS:
S+>> symbol:    a  symbol,  typically  the  result  of   symbol.C   or
S+>>        symbol.For.
S+>> name:     a character string giving the name of a subroutine.
S+>> 
S+>> VALUE:
S+>>        is.loaded returns a logical  value:  it  is  TRUE  if  the
S+>>        symbol  is  found  in  the  S-PLUS  symbol table and FALSE
S+>>        otherwise.  symbol.C returns  the  symbol  that  would  be
S+>>        produced  by  a C function named name.  symbol.For returns
S+>>        the symbol that would be produced by a Fortran  subroutine
S+>>        named  name.   symbol.S  returns  the symbol that would be
S+>>        produced by an old-S  function  named  name.   dump.loaded
S+>>        returns  a  list  with two components, symbol and address,
S+>>        giving the names and addresses of all cached symbols (this
S+>>        is  a  superset  of  all  dyn.loaded functions).  Applying
S+>>        is.loaded to any symbol in this list should return TRUE.
S+>> 
S+>> DETAILS:
S+>>        These functions  are  mainly  useful  for  writing  S-PLUS
S+>>        functions  that  will automatically dyn.load code if it is
S+>>        not loaded already.  The S-PLUS function can be  the  same
S+>>        whether  the  code  is  statically  loaded  or dynamically
S+>>        loaded.
S+>> 
S+>>        The symbol.S function is only useful for  those  who  have
S+>>        old-S  (S-PLUS  version 1.x) functions (not macros) and do
S+>>        not wish to convert them to .Fortran calls.
S+>> 
S+>> SEE ALSO:
S+>>        dyn.load, dyn.load2, LOAD, .Fortran, .S.
S+>> 
S+>> EXAMPLES:
S+>>        if (!is.loaded(symbol.C("mbol")))
S+>>                       dyn.load("/usr/mabel/mbol.o")
S+>>        .C("mbol",as.double(x),as.integer(length(x)))


----------------------------------------------------------------------
TASK:	"rep" problem
STATUS:	Closed
FROM:	<maechler@stat.math.ethz.ch>
	rep(1,0) gives  'Error: subscript out of bounds'
	Here is the new  ../src/library/base/funs/rep   
                    -------------------------
	(which contains two patches, the first of which I posted on May 20):

rep <- function(x, times, length.out)
{
        if (length(x) == 0)
                return(x)
        if (missing(times))
                times <- ceiling(length.out/length(x))
        r <- .Internal(rep(x,times))
        if(!is.null(nm <- names(x))) names(r) <- .Internal(rep(nm, times))
        if (!missing(length.out))
                return(r[if(length.out>0) 1:length.out else integer(0)])
        return(r)
}

----------------------------------------------------------------------
TASK:
STATUS:
FROM:
----------------------------------------------------------------------
TASK:
STATUS:
FROM:
----------------------------------------------------------------------
TASK:
STATUS:
FROM:
----------------------------------------------------------------------
TASK:
STATUS:
FROM:
----------------------------------------------------------------------
TASK:
STATUS:
FROM:
----------------------------------------------------------------------
TASK:
STATUS:
FROM:
----------------------------------------------------------------------


